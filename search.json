[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aprendizaje máquina supervisado con R",
    "section": "",
    "text": "Prefacio\nEn este taller exploramos aspectos prácticos del diseño, implementación y evaluación de modelos de aprendizaje automático supervisado. Estos modelos pueden aplicarse en múltiples problemas donde el objetivo es generar predicciones sobre nuevos datos, gracias a que el algoritmo ha sido previamente entrenado con un conjunto de datos que describe el problema a resolver.\nEste es un taller práctico que presenta ejemplos reales y comandos para entrenar, evaluar y aplicar modelos de aprendizaje automático supervisado con R. Además, junto a la explicación de los conceptos clave para entender este proceso también se ofrecen recomendaciones sobre buenas prácticas metodológicas para el ajuste (entrenamiento) de estos modelos, para comparar y elegir el algoritmo o modelo más adecuado para una aplicación específica, así como herramientas para interpretar mejor los resultados obtenidos.\nLos apuntes para este taller práctico se han realizado con Quarto, una herramienta para creación de documentación científica y programación literaria compatible con R y otros lenguajes de programación científica.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#requisitos-previos",
    "href": "index.html#requisitos-previos",
    "title": "Aprendizaje máquina supervisado con R",
    "section": "Requisitos previos",
    "text": "Requisitos previos\nPara poder realizar los ejemplos inlcuidos en este taller necesitas tener instalado R y una IDE de desarrollo para este lenguaje. Se recomienda instalar RStudio o MS Visual Code como entorno de programación.\n\nInstalación de R.\nInstalación de RStudio.\n\nAdicionalmente, es necesario instalar una serie de paquetes R antes de ejecutar los ejemplos, para que todas las dependencias estén disponibles en nuestro sistema. Consulta el Apéndice ?sec-pkg-requirements para comprobar el listado de paquetes R necesarios.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "01-introduccion.html",
    "href": "01-introduccion.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 Tipos de aprendizaje automático\nExisten muchas definiciones complementarias sobre la Inteligencia Artificial (IA), cada una reflejo de un modo diferente de aproximarse al complejo problema de crear máquinas que puedan imitar la inteligencia humana (Russell & Norvig, 2009). Por ejemplo, en el artículo de Wikipedia sobre IA se define de la siguiente forma enlace:\nEn 1950, Alan Turing propuso el llamado Test de Turing para proporcionar una definción operativa satisfactoria sobre “inteligencia”. En teoría, un computador supera el test si un interrogador humano, después de plantear varias preguntas, no es capaz de discernir si las respuestas escritas provienen de una persona o de un computador. Para poder superar el test, un computador necesitaría incluir muchas habilidades. Aunque el test original no lo contemplaba, el llamado Test de Turing total incorpora una señal de vídeo para que el interrogador pueda evaluar las habilidades de percepción y reacción físicas del sujeto. Entre otros aspectos, esto implica contar con habilidades como:\nPor tanto, vemos que el aprendizaje automático (machine learning o ML en inglés) es una rama de la IA que tiene por objetivo el desarrollo de técnicas y métodos para que las computadoras aprendan. Un agente inteligente aprende cuando es capaz de mejorar su rendimiento a partir de la experiencia y de la información extraída de datos.\nExiste una taxonomía ampliamente aceptada para clasificar las diferentes aproximaciones para resolver el problema del aprendizaje automático (Russell & Norvig, 2009):",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#tipos-de-aprendizaje-automático",
    "href": "01-introduccion.html#tipos-de-aprendizaje-automático",
    "title": "1  Introducción",
    "section": "",
    "text": "Aprendizaje supervisado: el agente observa algunos ejemplos de parejas de valores entrada-salida y aprende una función que mapea nuevas entradas a nuevos valores de salida.\nAprendizaje no supervisado: el agente debe descubrir patrones o similitudes entre los valores de entrada aunque no se le haya facilitado ningún tipo de información adicional.\nAprendizaje semisupervisado: combina los dos anteriores, puesto que el agente recibe sólo unos pocos ejemplos y, a partir de ellos, tiene que hacer lo posible por descubrir patrones en una colección de ejemplos no etiquetados o explicados.\nAprendizaje por refuerzo: el método de aprendizaje implica que el agente reciba premios o castigos. Por ejemplo, si un agente aprende a jugar al ajedrez y recibe dos puntos por haber ganado una partida, deduce que lo ha hecho bien. Por contra, si un agente de conducción registra un aviso de choque recibe una penalización para indicarle que lo ha hecho mal.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#tareas-de-aprendizaje-automático-supervisado",
    "href": "01-introduccion.html#tareas-de-aprendizaje-automático-supervisado",
    "title": "1  Introducción",
    "section": "1.2 Tareas de aprendizaje automático supervisado",
    "text": "1.2 Tareas de aprendizaje automático supervisado\nEn este taller práctico nos vamos a centrar en el aprendizaje supervisado, cuyo fin principal es el de predecir el valor de salida que corresponde a una combinación concreta de valores descriptivos de entrada. Los dos tipos de tareas que se suelen abordar en aprendizaje automático supervisado son (Boehmke & Greenwell, 2019):\n\nRegresión: el objetivo es predecir una salida numérica, cuyos valores se distribuyen a lo largo de un contínuo. Por ejemplo, un modelo que prediga el valor de venta de una viviendia en función de varios datos descriptivos sobre la misma (superficie construida, año de construcción, número de habitaciones, ubicación, etc.) es un modelo de regresión. No se debe confundir con el término “regresión lineal”, que es un tipo específico de modelo de aprendizaje.\nClasificación: el objetivo es predecir una salida categórica (etiqueta), que puede tener dos posibles valores (clasificación binaria) o varios valores (clasificación multinomial).\n\n\n\n\n\n\n\nFigura 1.1: Ejemplo de salida de un modelo de predicción de valor de venta de viviendas en función de su año de construcción y superficie útil. Figura tomada de (Boehmke & Greenwell, 2019), sección 1.1.1.\n\n\n\n\n\n\n\n\n\nFigura 1.2: Ejemplo un modelo de clasificación binaria, en función de tres parámetros descriptivos de entrada. Figura tomada de (Boehmke & Greenwell, 2019), sección 1.1.2.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#ajuste-de-modelos",
    "href": "01-introduccion.html#ajuste-de-modelos",
    "title": "1  Introducción",
    "section": "1.3 Ajuste de modelos",
    "text": "1.3 Ajuste de modelos\nEl ajuste de un modelo de aprendizaje automático comprende una secuencia de pasos o tareas que permite que el algoritmo o modelo seleccionado aprenda a resolver un problema concreto. Es decir, que aprenda a predecir un valor de salida en función de una combinación de valores de entrada.\n\n\n\n\n\n\nNota\n\n\n\nDependiendo de si estamos hablando con personas que provienen del aprendizaje estadístico, las ciencias de la computación o el reconocimiento de patrones, encontraremos términos diferentes para designar a un mismo procedimiento. Por ejemplo, alguien de aprendizaje estadístico dirá que va a ajustar un modelo, en el sentido de calcular, a partir de datos, el valor de los parámetros que lo determinan. Sin embargo, alguien de computación (aprendizaje automático) hablará más bien de entrenar un algoritmo con datos, lo que trae consigo elegir valores para sus parámetros.\nLa única diferencia, por tanto, es en qué parte del mismo proceso se pone el foco en cada caso. En muchas ocasiones, en este taller usaremos indistintamente los términos ajuste o entremaiento aplicados a un modelo o algoritmo.\n\n\nEl proceso completo de ajuste o entrenamiento de un modelo se mostrará en la Figura 2.1 en el Capítulo 2. El primer paso en esta secuencia de ajuste de modelos siempre es la división del conjunto de datos en dos grupos (Boehmke & Greenwell, 2019):\n\nDatos de entrenamiento (training): son los datos que vamos a emplear para que el algoritmo/modelo aprenda a resolver el problema. Entre otros aspectos, permiten elegir las variables o entradas que vamos a utilizar, calcular valores óptimos para los hiperparámetros del modelo, comparar el rendimiento de varios modelos y el resto de acciones que conducen a elegir un modelo final.\nDatos de prueba: una vez que hemos seleccionado un modelo final, estos datos sirven para obtener una estimación no sesgada del rendimiento de nuestro modelo cuando se enfrenta a datos que no ha visto previamente, lo que denominamos error de generalización.\n\n\n\n\n\n\n\nFigura 1.3: División básica de datos en grupos de entrenamiento y prueba (training/testing)\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEs de vital importancia garantizar que los datos de prueba (testing) nunca se usan durante el entrenamiento del modelo/algoritmo. De otro modo, la selección del modelo final podría verse comprometida (introducción de sesgo).\n\n\nLos porcentajes del total del datos que se recomendia usar para cada grupo suelen oscilar entre 60% (training) - 40% (testing), 70%-30% u 80%-20%. Usar más del 80% de los datos para entrenamiento sería contraproducente, puesto que no tendríamos suficientes datos como para hacer una valoración adecuada del modelo y, además, el ajuste encajaría demasiado en los datos observados y perdería capacidad de generalización (sobreajuste, overfitting en inglés). Por contra, emplear demasiados datos en probar el modelo (&gt;40%) implicaría no tener suficientes datos como para ajustar sus parámetros de manera robusta.\nNo obstante, existen casos particulares. Si tenemos un dataset de gran tamaño, entonces no tiene demasiado sentido crear un conjunto de entrenamiento muy grande, ya que la mayoría de los algoritmos de aprendizaje automático (exceptuando, por ejemplo, los modelos basados en aprendizaje profundo más recientes) no obtienen ningún beneficio por utilizar muchos datos para entrenarlos. Por otro lado, si \\(n\\) es el tamaño de nuestro dataset y \\(p\\) el número de variables o features de entrada del modelo, cuando \\(p&gt;&gt;n\\) sí se necesitan grandes conjuntos de datos para estimar de manera fiable posibles patrones en los datos.\nLa pregunta es: ¿cómo podemos dividir nuestros datos en los conjuntos de entrenamiento y prueba? Para resolver esta tarea se aplican técnicas de muestreo de datos. A continuación, se describen algunas opciones habituales.\n\n1.3.1 Técnicas de muestreo\nNormalmente, la división de los datos en estos dos grupos se realiza por medio de técnicas de muestreo. Las dos técnicas más comúnmente aplicadas son:\n\nMuestreo aleatorio simple: es la forma más sencilla, consiste en tomar aleatoriamente muestras de los datos hasta llenar cada uno de los grupos. La gran desventaja de este método es que no tiene en cuenta distribuciones específicas de los datos en el conjunto original (por ejemplo, para preservar la proporción de datos presentes en cada categoría). Un ejemplo lo podemos ver en la Figura 1.4.\nMuestreo estratificado: se utiliza cuando necesitamos controlar explícitamente que nuestros conjuntos de entrenamiento y de prueba tengan distribuciones de valores similares a las del conjunto de datos original. Podemos ver un ejemplo en la Sec. 2.2.2 de (Boehmke & Greenwell, 2019).\n\n\n\n\n\n\n\nFigura 1.4: El muestreo aleatorio simple no tiene en cuenta la proporción de datos existente en el conjunto original. En este caso, después del muestreo el conjunto de entrenamiento mantiene aproximadamente estas proporciones, pero el de prueba no. Figura tomada de (Raschka, 2020).\n\n\n\n\n\nParticionado de datos con R\nEn este apartado presentamos algunos ejemplos de implementación del proceso de particionado de datos en R, empleando varios paquetes.\nDataset: AmesHousing: Información sobre ventas de propiedades inmobiliarias descrito en (De Cock, 2011) y proporcionado por el paquete AmesHousing (Kuhn, 2020).\n\n\n\nTabla 1.1: Descripción del dataset proporcionado por el paquete AmesHousing.\n\n\n\n\n\nDescripción\nValor\n\n\n\n\nTipo de problema\nRegresión (supervisada)\n\n\nRespuesta\nSales_Price, cuantitativa\n\n\nVariables (inputs)\n80\n\n\nObservaciones\n2.930\n\n\nObjetivo\nPredicción del precio de las viviendas\n\n\nMás información\n?AmesHousing::ames_raw\n\n\n\n\n\n\n\nlibrary(dplyr)    # Procesado y filtrado de datos\nlibrary(ggplot2)  # Gráficos\nlibrary(patchwork)\n\n# Paquetes para preparación y modelado de datos\nlibrary(rsample)  # Técnicas de remuestreo\nlibrary(caret)    # Remuestreo y entrenamiento (Kuhn & Johnson)\nlibrary(h2o)      # Remuestreo y entrenamiento (H2O.ai)\n\n# Configuración inicial de h2o\nh2o.no_progress()  # Deshabilita barra de progreso de h2o\nh2o.init()         # Lanza el cluster (local) de h2o\n\n\nH2O is not running yet, starting it now...\n\nNote:  In case of errors look at the following log files:\n    /tmp/Rtmps3zO24/file5d5367aa8ee9/h2o_jfelipe_started_from_r.out\n    /tmp/Rtmps3zO24/file5d53239829d9/h2o_jfelipe_started_from_r.err\n\n\nStarting H2O JVM and connecting: ... Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         1 seconds 461 milliseconds \n    H2O cluster timezone:       Europe/Madrid \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    1 year, 11 months and 4 days \n    H2O cluster name:           H2O_started_from_R_jfelipe_lgd607 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   7.78 GB \n    H2O cluster total cores:    12 \n    H2O cluster allowed cores:  12 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.5.2 (2025-10-31) \n\n\nWarning in h2o.clusterInfo(): \nYour H2O cluster version is (1 year, 11 months and 4 days) old. There may be a newer version available.\nPlease download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n\n\n\names &lt;- AmesHousing::make_ames()\names.h2o &lt;- as.h2o(ames)\n\n\nMuestreo aleatorio simple\n\n# Con R Base\nset.seed(123)  # Fijamos semilla, resultados reproducibles\n\nindex_1 &lt;- sample(1:nrow(ames), round(nrow(ames) * 0.7))\ntrain_1 &lt;- ames[index_1, ]\ntest_1  &lt;- ames[-index_1, ]\n\n# Usando el paquete caret\nset.seed(123)  # Resultados reproducibles\nindex_2 &lt;- createDataPartition(ames$Sale_Price, p = 0.7, \n                               list = FALSE)\ntrain_2 &lt;- ames[index_2, ]\ntest_2  &lt;- ames[-index_2, ]\n\n# Usando el paquete rsample\nset.seed(123)  # Resultados reproducibles\nsplit_1  &lt;- initial_split(ames, prop = 0.7)\ntrain_3  &lt;- training(split_1)\ntest_3   &lt;- testing(split_1)\n\n# Usando el paquete h2o\nsplit_2 &lt;- h2o.splitFrame(ames.h2o, ratios = 0.7, seed = 123)\ntrain_4 &lt;- split_2[[1]]\ntest_4  &lt;- split_2[[2]]\n\nLa Figura 1.5 muestra varios paneles donde podemos comprobar la distribución de valores de las diferenes particiones, respecto de los datos originales.\n\n\nMostrar código\ncompara_dens &lt;- function(orig, train, test, var_name, main_title,\n    name_orig = deparse(substitute(original)),\n    name_train = deparse(substitute(train)),\n    name_test = deparse(substitute(test))) {\n    \n    datos_combinados &lt;- data.frame(\n    valor = c(orig, train, test),\n    grupo = c(rep(name_orig, length(orig)),\n        rep(name_train, length(train)), \n        rep(name_test, length(test)))\n    )\n\n    p &lt;- ggplot(datos_combinados, aes(x = valor, color = grupo)) +\n    geom_density(alpha = 0.4) + # 'alpha' controla la transparencia (0 a 1)\n    labs(\n        title = main_title,\n        subtitle = \"Comparación train vs. test\",\n        x = var_name,\n        y = \"Densidad\",\n        color = \"Variable\"\n    ) +\n    theme_minimal() + theme(legend.position=\"none\")\n\n    return(p)\n}\n\np1 &lt;- compara_dens(ames$Sale_Price, train_1$Sale_Price, test_1$Sale_Price, \"Sale_Price\", \"R base\")\np2 &lt;- compara_dens(ames$Sale_Price, train_2$Sale_Price, test_2$Sale_Price, \"Sale_Price\", \"caret\")\np3 &lt;- compara_dens(ames$Sale_Price, train_3$Sale_Price, test_3$Sale_Price, \"Sale_Price\", \"rsample\")\np4 &lt;- compara_dens(ames$Sale_Price, as.data.frame(train_4)$Sale_Price, \n                   as.data.frame(test_4)$Sale_Price, \"Sale_Price\", \"h2o\")\n\nwrap_plots(p1, p2, p3, p4)\n\n\n\n\n\n\n\n\nFigura 1.5: Comparación de las distribuciones de valores obtenidas en las muestras. Rojo: datos originales; azul: partición de entrenamiento; verde: partición de prueba.\n\n\n\n\n\n\n\nMuestreo estratificado\nConsultar el ejemplo de la Sec. 2.2.2 en (Boehmke & Greenwell, 2019), que explica cómo utilizar el paquete rsample para obtener un muestreo estratificado.\nTambién es bastante directo obtener un muestreo estratificado usando Tidyverse.\n\n\n\n1.3.2 Desequilibrios en los datos\nOtro aspecto que también tenemos que considerar es si existe algún tipo de desequilibrio entre las categorias o la distribución de valores de nuestro conjunto de datos. Esto ocurre, por ejemplo, en datos etiquetados en los que una categoría tiene muchas menos instancias que otras, como en los problemas de fraude o impagos. En un dataset con dos categorías, \"fraudulento\" o \"legítimo\", si la primera categoría tiene sólo un 1% del total de muestras y la segunda el 99% restante será difícil que los conjuntos de entrenamiento y prueba mantengan esa proporción. Por otro lado, también será complicado que el modelo pueda aprender a identificar instancias de la categoría minoritaria si tiene pocos ejemplos de los que poder aprender a reconocerla. Por ello, existen varias técnicas para mitigar esta limitación:\n\nSubmuestreo (down-sampling): reduce el tamaño de la clase más frecuente para que corresponda con la proporción de instancias en la clase minoritaria. Se puede usar si el conjunto de datos original es grande.\nSobremuestreo (up-sampling): si no hay muchos datos en el conjunto original, otra solución es utilizar técnicas de remuestreo (como bootstraping) para generar nuevas muestras “artificiales” de la clase minoritaria.\nSMOTE: combina los dos métodos anteriores de forma innovadora.\n\nSe pueden utilizar estos métodos en R mediante el argumento sampling en caret::trainControl() , así como en otros paquetes (como h2o).",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#preparación-de-los-datos",
    "href": "01-introduccion.html#preparación-de-los-datos",
    "title": "1  Introducción",
    "section": "1.4 Preparación de los datos",
    "text": "1.4 Preparación de los datos\nAntes de presentar algunos ejemplos de modelos supervisados de aprendizaje máquina y cómo podemos emplearlos en R, conviene recordar que un paso previo imprescindible es preparar adecuadamente nuestros datos. Con demasiada frecuencia, errores de codificación, ausencia de valores, escalas de representación demasiado amplias y muchos otros problemas aparecen en nuestros datos y pueden malograr todos nuestros esfuerzos por conseguir ajustar nuestros modelos y elegir la opción más adecuada.\nLas tareas de limpieza y preparación de datos podrían llenar un taller o un curso entero por sí mismas. Se invita al lector a consultar el capítulo 3 de (Boehmke & Greenwell, 2019), así como las referencias (Kuhn & Johnson, 2019) y (Zheng & Casari, 2018) para un tratamiento más detallado de muchas de las tareas de limpieza y preparación de datos necesarias antes de implementar y evaluar nuestros modelos de aprendizaje automático.\n\n\n\n\nBoehmke, B., & Greenwell, B. (2019). Hands-On Machine Learning with R (1.ª ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nDe Cock, D. (2011). Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project. Journal of Statistics Education, 19(3). https://doi.org/10.1080/10691898.2011.11889627\n\n\nKuhn, M. (2020). AmesHousing: The Ames Iowa Housing Data. https://doi.org/10.32614/CRAN.package.AmesHousing\n\n\nKuhn, M., & Johnson, K. (2019). Feature Engineering and Selection: A Practical Approach for Predictive Models. Chapman & Hall/CRC. http://www.feat.engineering/\n\n\nRaschka, S. (2020). Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning. https://arxiv.org/abs/1811.12808\n\n\nRussell, S., & Norvig, P. (2009). Artificial Intelligence: A Modern Approach (3.ª ed.). Prentice Hall Press.\n\n\nZheng, A., & Casari, A. (2018). FFeature Engineering for Machine Learning: Principles and Techniques for Data Scientists. O’Reilly Media, Inc. https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "02-ml-supervisado.html",
    "href": "02-ml-supervisado.html",
    "title": "2  Aprendizaje máquina supervisado",
    "section": "",
    "text": "2.1 Parámetros e hiperparámetros\nComo hemos introducido en el tema anterior, el aprendizaje máquina supervisado es un proceso que implica entrenar a un algoritmo computacional para que resuelva un problema de predicción (regresión o clasificación), utilizando para ello un conjunto de datos. La Figura 2.1 muestra un esquema del proceso completo.\nAntes de profundizar un poco en todo este proceso, conviene puntualizar el significado de un par de términos que suelen provocar bastante confusión.\nDurante el proceso de aprendizaje, el algoritmo o modelo escogido puede ajustar el valor de ciertos parámetros a partir de la información extraída de los datos. Pensemos, por ejemplo, en un modelo de regresión lineal. Dicho modelo, constará de una serie de parámetros (coeficientes), \\(\\{\\beta_0, \\beta_1, \\beta_2, \\dots, \\beta_p\\}\\), cuyo valor podemos ajustar a partir de \\(p\\) variables de entrada proporcionadas al sistema, \\(\\{x_1, x_2, \\dots, x_p\\}\\) para predecir el valor esperado de la variable de salida (respuesta), \\(y\\). En su caso más sencillo, la regresión lineal plantea la ecuación:\n\\[y = \\beta_0 + \\beta_1x_1+\\beta_2x_2+\\dots+\\beta_px_p\\]\nLos valores de los parámetros (coeficientes) \\(\\beta_i\\) se pueden calcular a partir de los datos de entrenamiento. En este caso tan sencillo, todos los parámetros del modelo son calculados a partir de los datos. Sin embargo, en otros casos, además de estos parámetros ajustables a partir de los datos hay que fijar los valores de uno o varios parámetros adicionales, que no pueden deducirse directamente de los datos. Estos son los denominados hiperparámetros, cuyo valor hay que fijar estimándolo de algún modo. Un ejemplo serían los modelos de regresión con regularización, un tipo de penalización que permite minimizar o directamente anular la intervención de las variables de entrada en el resultado de la predicción. Dos variantes comunes en este apartado son la regresión Ridge y Lasso, cuyo parámetro \\(\\alpha\\) controla la “intensidad” del procedimiento de regularización aplicado.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aprendizaje máquina supervisado</span>"
    ]
  },
  {
    "objectID": "02-ml-supervisado.html#el-problema-del-sobreajuste",
    "href": "02-ml-supervisado.html#el-problema-del-sobreajuste",
    "title": "2  Aprendizaje máquina supervisado",
    "section": "2.2 El problema del sobreajuste",
    "text": "2.2 El problema del sobreajuste\nObserva la Figura 2.2, en la que se muestra un pequeño conjunto de datos representado en un diagrama de dispersión en 2-D. Sobre el diagrama de dispersión, tenemos dos posibles modelos candidatos, ajustados a estos datos:\n\nUn modelo lineal simple que, por ejemplo, podríamos haber obtenido mediante un ajuste por mínimos cuadrados.\nUn polinomio de grado \\(n-1\\) (donde \\(n\\) es el número de datos disponibles), que se ajusta perfectamente a todos los datos observados.\n\n\n\n\n\n\n\nFigura 2.2: Ejemplo de sobreajuste de un modelo. La función polinómica (en azul) se ajusta perfectamente a los datos (puntos en negro), pero no generaliza para otros datos nuevos. Fuente: Overfitting, Wikipedia.\n\n\n\nComo podemos apreciar, el modelo lineal simple comete cierto error en su ajuste, ya que algunos puntos quedan ligeramente por encima o por debajo de la recta de regresión propuesta. Sin embargo, el polinomio de grado \\(n-1\\) tiene error nulo, su ajuste es perfecto.\n¿Qué modelo elegiríamos? Podríamos estar tentados de elegir el polinomio, al tener un error menor. Sin embargo, esta sería una elección poco acertada. No es muy creíble que, cualquiera que fuese el proceso que dio origen a estos datos, siga una evolución tan complicada como la marcada por las repetidas (y retorcidas) curvas de ese polinomio. La pregunta clave es no es cuánto error cometemos con los datos de entrenamiento sino cuánto error comete el modelo al tratar de predecir los datos de prueba, que no debe haber visto nunca antes.\nEste problema, clave en el proceso de ajuste/entrenamiento de modelos supervisados, es lo que conocemos como sobreajuste (overfitting). Como norma general, que nunca debemos olvidar, al ajustar un modelo/algoritmo mediante datos tenemos que cuidar que no pierda su capacidad para generalizar, es decir, para predecir con poco margen de error nuevos datos a los que no se haya enfrentando antes.\nEn palabras de George E. P. Box, uno de los más geniales contribuyentes a la práctica estadística del siglo XX y comienzos del XXI, :\n\n“Remember that all models are wrong; the practical question is how wrong do they have to be to not be useful.”\n\n\n\n\n\n\n\nFigura 2.3: George E. P. Box (1919-2013)\n\n\n\nEste principio de generalización debe de completarse con otra prerrogativa, el llamado principio de parsimonia (también conocido como “navaja de Occam”). Este segundo principio nos dicta que debemos favorecer los modelos más sencillos frente a los más complicados, puesto que serán más fáciles de interpretar.\nNo obstante, conviene recordar las palabras de A. Einstein:\n\n“Everything should be made as simple as possible, but not simpler.”\n\nLa traducción de esta advertencia, en términos de nuestro procedimiento para ajustar modelos de aprendizaje automático, es que también debemos evitar el subajuste (underfitting), provocado por un modelo que no ha sido entrenado convenientemente y todavía podría ofrecer menor error de entrenamiento sin incrementar el error de generalización.\n\n\n\n\n\n\nFigura 2.4: Ilustración del efecto del subajuste y el sobreajuste ajustando un modelo de regresión lineal a un conjunto de datos. El modelo parabólico del centro ofrece una buena solución de compromiso. Fuente: https://medium.com/@kiprono_ek/regularization-a-technique-used-to-prevent-over-fitting-886d5b361700.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aprendizaje máquina supervisado</span>"
    ]
  },
  {
    "objectID": "02-ml-supervisado.html#el-balance-sesgo-varianza",
    "href": "02-ml-supervisado.html#el-balance-sesgo-varianza",
    "title": "2  Aprendizaje máquina supervisado",
    "section": "2.3 El balance sesgo-varianza",
    "text": "2.3 El balance sesgo-varianza\nEl “punto de equilibrio” al que hacemos referencia en el apartado anterior está directamente relacionado con dos conceptos esenciales que midel el error cometido por los modelos entrenados en aprendizaje automático (Boehmke & Greenwell, 2019):\n\nSesgo (bias): es la diferencia entre el valor esperado (o promedio) que predice nuestro algoritmo y el valor correcto que estamos intentando predecir. Dicho de otro modo, mide cómo de lejos se quedan los valores predichos por nuestro modelo respecto de los valores reales.\nVarianza (variance): es la “imprecisión” (error) que tienen las predicciones generadas por nuestro modelo para un valor de salida específico. Normalmente, un excesivo error en las predicciones para valores concretos de salida está relacionado con el sobreajuste, al haberse fijado el modelo demasiado en las fluctuaciones de los datos de entrenamiento, evitando así que generalice de forma más precisa para otros casos.\n\nLa Figura 2.5 muestra un esquema de los diferentes errores cometidos durante el proceso de aprendizaje, y dónde se encontraría un posible punto de compromiso, en la zona intermedia del gráfico, en el que se localiza un mínimo error de entrenamiento (para evitar subajuste), impidiendo que crezca de nuevo el error de generalización (lo que evita el sobreajuste).\n\n\n\n\n\n\nFigura 2.5: Ilustración esquemática del sesgo y la varianza en el proceso de entrenamiento de un modelo de aprendizaje máquina supervisado. La zona a la izquierda del punto de compromiso deseado corresponde al subajuste, mientras que la zona a la derecha del punto de compromiso implica caer en sobreajuste. Fuente: https://sebastianraschka.com/pdf/lecture-notes/stat451fs20/08-model-eval-1-intro__slides.pdf.\n\n\n\nLa Figura 2.6 trata de ilustrar el tipo de error cometido en cada caso, comparando nuestras predicciones con lanzamientos sobre una diana (en rojo), asumiendo que la predicción correcta consiste en acertar en el centro de la diana.\n\n\n\n\n\n\nFigura 2.6: Representación conceptual del sesgo y la varianza en predicción de modelos de aprendizaje automático, suponiendo que se tratasen de lanzamientos sobre una diana. Fuente: (Raschka, 2020).\n\n\n\nComo resulta evidente en esta representación, la situación ideal sería la de un modelo que, simultáneamente, consiguiese predicciones con pocas fluctuaciones (varianza pequeña) y cercanas al valor real (mínimo sesgo). Sin embargo, en muchos casos reales no es posible conseguir ambos objetivos al mismo tiempo, y debemos optar por elegir la solución de compromiso que mejor refleje nuestros intereses.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aprendizaje máquina supervisado</span>"
    ]
  },
  {
    "objectID": "02-ml-supervisado.html#sec-cross-validation",
    "href": "02-ml-supervisado.html#sec-cross-validation",
    "title": "2  Aprendizaje máquina supervisado",
    "section": "2.4 Procedimiento de validación cruzada",
    "text": "2.4 Procedimiento de validación cruzada\nEn el contexto que hemos descrito, se sabe que sin un conocimiento previo sobre un problema concreto o el conjunto de datos que vamos a utilizar, es difícil asegurar a priori cuál será el mejor modelo o algoritmo de aprendizaje automático que lo resuelva. Esta limitación se conoce como el teorema no free lunch (Wolpert, 1996).\nPuesto que debemos comparar los posibles modelos candidatos antes de utilizar los datos del conjunto de testing, una posible opción es utilizar los propios datos de entrenamiento para medir el rendimiento de cada modelo y compararlos entre sí. Sin embargo, este procedimiento no es adecuado porque, como ya sabemos, algunos modelos se pueden comportar muy bien con los datos de entrenamiento, pero generalizan mal con otros datos nuevos.\nOtra opción es la de utilizar un método de validación, en el que parte del conjunto de datos de entrenamiento se utilicen para entrenar el modelo y otra parte, el conjunto de validación (holdout set) se guarde para validar el modelo, sin usar aún el conjunto de prueba final, que queda al margen de este proceso.\nSin embargo, usar un solo conjunto de validación puede dar como resultado malas estimaciones (se pueden consultar las referencias ofrecidas en apartado 2.4 de (Boehmke & Greenwell, 2019)). La mejor opción es usar un método de remuestreo (resampling). La idea es repetir el ajuste del modelo sobre distintas fracciones de los datos de entrenamiento y evaluar su rendimiento sobre otras partes. Los dos métodos más habituales que se aplican en estos casos son:\n\nValidación cruzada con \\(k\\) conjuntos (k-fold cross validation).\nBootstrapping, basada en la conocida técnica bootstrap de remuestreo: una muestra aleatoria con reemplazo de los datos originales (Efron & Tibshirani, 1993).\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEs importante saber que en algunos textos y referencias sobre métodos de validación, se denomina indistintamente a los sucesivos conjuntos de datos de validación dentro de grupo de datos de entrenamiento como “prueba”, “test”, “validación”, “evaluación”, etc. Esto genera gran confusión, puesto que es difícil distinguir cuándo se referieren a estos conjuntos y cuándo están hablando de los datos de evaluación finales, que permanecen al margen durante todo el proceso hasta que tenemos que evaluar el modelo final seleccionado.\nEn consecuencia, lo importante es tener claro el esquema mental del proceso que estamos siguiendo, para interpretar adecuadamente la denominación que utilicemos en cada referencia.\n\n\n\n2.4.1 Validación cruzada con k conjuntos\nLa Figura 2.7 muestra en un esquema cómo se implementa este método de validación.\n\n\n\n\n\n\nFigura 2.7: Esquema que explica el procedimiento de validación cruzada con k conjuntos. Fuente: Sec. 2.4.1 de (Boehmke & Greenwell, 2019).\n\n\n\n\nEl conjunto global de datos de entrenamiento se divide en \\(k\\) trozos o subconjuntos.\nEn cada iteración, uno de los trozos se reserva para validar los modelos y los otros \\(k-1\\) trozos se usan para entrenar los modelos.\nPor último, para cada modelo se combinan (calculando el promedio o de otras formas) las evaluaciones individuales en cada iteración para ofrecer un resultado de evaluación global, que se compara con el resto de modelos para seleccionar el más adecuado.\n\nLo más habitual es usar valores \\(k=5\\) o \\(k=10\\) (Boehmke & Greenwell, 2019). Cuanto mayor sea \\(k\\) menor será la diferencia entre el rendimiento real y nuestra estimación, pero también será mayor el coste computacional para completar el procedimiento.\n\n2.4.1.1 k-fold cross validation con R\nLa mayoría de paquetes orientados al entrenamiento y evaluación de modelos de aprendizaje automático en R ya incluyen argumentos para indicar el tipo de validación cruzada que queremos realizar.\nPor ejemplo, la función h2o::h2o.glm() para ajuste de modelos GLM (véase Sección 3.3), incluye el argumento de entrada nfolds para controlar cuántos grupos usaremos en el procedimiento de validación cruzada. Si nfolds = 0 no se aplica validación cruzada.\n\nh2o.cv &lt;- h2o.glm(\n  x = x, \n  y = y, \n  training_frame = ames.h2o,\n  nfolds = 10  # realiza 10-fold CV\n)\n\nEl paquete rsample contiene la función rsample::vfold_cv() que devuelve un data frame anidado. Cada elemento en splits es una lista que contiene el data frame de entrenamiento en esa iteración y los IDs de las observaciones que se usarán para entrenar vs. validar el modelo.\n\nvfold_cv(ames, v = 10) # prepara 10-fold CV\n\n\n\n\n2.4.2 Boostrapping\nLa Figura 2.8 muestra un esquema de cómo se realiza el proceso de muestreo con reemplazo o bootstrapping.\n\n\n\n\n\n\nFigura 2.8: Esquema que explica el procedimiento de bootstrapping. Fuente: Sec. 2.4.2 de (Boehmke & Greenwell, 2019).\n\n\n\nEn promedio, un 63,21% de las muestras originales son seleccionadas en cada muestra boostrap, mientras que las restantes que no han sido seleccionadas se marcan como out-of-bag (OOB). En este procedimiento, podemos entrenar un modelo con la muestra boostrap y validarlo con las muestras OOB. Por ejemplo este es el método empleado por Random Forests.\nEste procedimiento tiende a reducir la varianza de la estimación, pero en conjuntos de datos no muy grandes (&lt; 1.000 muestras) puede incrementar el sesgo de la estimación de rendimiento. En la mayoría de conjuntos de datos actuales, con tamaños relativamente grandes, esto no suele constituir un problema.\n\nMuestras con bootstrapping en R\nLa función rsample::bootstraps() permite generar los conjuntos que necesitemos mediante bootstrapping.\n\nbootstraps(ames, times = 10)\n\n\n\n\n2.4.3 Otros métodos de validación cruzada\nExisten muchos otros métodos de validación cruzada que contemplan casos especiales o se aplican sobre datos con características particulares.\n\nValidación cruzada anidada: Método alternativo de validación que permite estimar los hiperparámetros y comparar al mismo tiempo modelos introduciendo menor sesgo (cf. Sec. 4.14 (Raschka, 2020)).\nLOOCV: es un caso extremo de validación cruzada con \\(k\\) conjuntos, en el que \\(k=n\\) (Kuhn & Johnson, 2013).\nValidación cruzada para series temporales: se aplica cuando tenemos datos con depencias temporales estrictas. Puedes consultar la sec. 5.10 de (Hyndman & Athanasopoulos, 2021) para aprender más sobre esta técnica.\n\nEn el extenso artículo sobre evaluación de modelos de aprendizaje automático de S. Raschka (Raschka, 2020) se pueden consultar más propiedades y consejos prácticos sobre métodos de validación.\n\n\n\n\nBoehmke, B., & Greenwell, B. (2019). Hands-On Machine Learning with R (1.ª ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nEfron, B., & Tibshirani, R. J. (1993). Bootstrap Methods and Their Application. Chapman; Hall/CRC.\n\n\nGrigorev, A. (2021). Machine Learning Bookcamp (1.ª ed.). Manning Publications Co. https://www.manning.com/books/machine-learning-bookcamp\n\n\nHyndman, R. J., & Athanasopoulos, G. (2021). Forecasting: Principles and Practice (3.ª ed.). OTexts. https://otexts.com/fpp3/\n\n\nKuhn, M., & Johnson, K. (2013). Applied Predictive Modeling. Springer New York. https://books.google.es/books?id=xYRDAAAAQBAJ\n\n\nRaschka, S. (2020). Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning. https://arxiv.org/abs/1811.12808\n\n\nWolpert, D. H. (1996). The Lack of A Priori Distinctions Between Learning Algorithms. Neural Computation, 8(7), 1341-1390. https://doi.org/10.1162/neco.1996.8.7.1341",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aprendizaje máquina supervisado</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html",
    "href": "03-algoritmos-modelos.html",
    "title": "3  Algoritmos y modelos",
    "section": "",
    "text": "3.1 Datasets\nEn este apartado, vamos a presentar algunos modelos de aprendizaje máquina supervisado que, posteriormente, mostraremos cómo se pueden entrenar y evaluar con R. Necesitaremos los siguientes paquetes.\nAdemás, será necesario tener instalados varios paquetes más que caret emplea internamente para ajustar cada tipo de algoritmo o modelo solicitado.\nAntes de comenzar, es importante hacer una distinción entre dos tipos de modelos o algoritmos (James, 2021):\nEn este capítulo vamos a utilizar el paquete caret en modo de ejecución paralela, para aprovechar las capacidades multi-núcleo de la mayoría de computadores modernos.\nDataset: Sonar: El objetivo es discriminar entre dos tipos de blancos detectados con un sistema sónar (Gorman & Sejnowski, 1988):\nEstá incluido en el paquete mlbench Blake & Merz (1998).",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html#datasets",
    "href": "03-algoritmos-modelos.html#datasets",
    "title": "3  Algoritmos y modelos",
    "section": "",
    "text": "Cilindro metálico.\nRoca aproximadamente cilíndrica.\n\n\n\n\n\nTabla 3.2: Descripción del dataset mlbench::Sonar.\n\n\n\n\n\nDescripción\nValor\n\n\n\n\nTipo de problema\nClasificación binaria (supervisada)\n\n\nRespuesta\nClass; etiquetas: M o R\n\n\nVariables (inputs)\n60; rango \\([0.0, 1.0]\\)\n\n\nObservaciones\n208\n\n\nObjetivo\nDistinguir tipo de blanco sónar\n\n\nMás información\n?mlbench::Sonar\n\n\n\n\n\n\n\n3.1.1 Particionado de datos\nDataset: mlbench::Sonar.\nLa preparación esta documentada en el paquete caret.\n\ndata(Sonar)\nSonarData = Sonar[,c(1,11,17,23,28,34,40,45,56,61)]\n\nset.seed(107)\ninTrain &lt;- createDataPartition(\n  y = SonarData$Class,  # se necesitan los datos de la salida\n  p = .75,              # 75% datos para entrenamiento\n  list = FALSE\n)\n## Formato de resultados\n\n## La salidad es un conjunto de enteros que representan los\n## índices de las filas en el dataset original escogidos para\n## entrar en el training set.\nstr(inTrain)\n\n int [1:157, 1] 1 2 3 4 5 7 10 11 12 13 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : NULL\n  ..$ : chr \"Resample1\"\n\ntraining &lt;- SonarData[ inTrain,]\ntesting  &lt;- SonarData[-inTrain,]\n\nnrow(training)\n\n[1] 157\n\nnrow(testing)\n\n[1] 51\n\n\nSólo queda configurar es sistema de evaluación cruzada para medir el rendimiento de los modelos antes de enfrentarse al conjunto final de prueba, así como para ajustar los hiperparámetros que sean necesarios. En todos los ejemplos aplicaremos validación cruzada con 5 grupos.\n\nconfig_control &lt;- trainControl(\n    method = 'cv',                   # k-fold cross-validation\n    # method = 'repeatedcv',         # k-fold cross-validation repetida (variante)\n    number = 5,                      # número de grupos o iteraciones de remuestreo\n    # repeats = 10,                  # número de conjuntos completos de grupos a computar\n    savePredictions = 'final',       # guardar las predicciones para ajuste óptimo de hiperparámetros\n    classProbs = TRUE,               # se devuelven las probabilidades de clase\n    summaryFunction=twoClassSummary  # tipo de función para resumir resultados (según el tipo de problema)\n)",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html#k-vecinos-más-cercanos-k-nn",
    "href": "03-algoritmos-modelos.html#k-vecinos-más-cercanos-k-nn",
    "title": "3  Algoritmos y modelos",
    "section": "3.2 K vecinos más cercanos (K-NN)",
    "text": "3.2 K vecinos más cercanos (K-NN)\nSe trata de un modelo que puede realizar funciones de regresión o clasificación. En el caso de la regresión, fijado un valor para \\(K\\) y un punto de predicción \\(x_0\\), se identifican las \\(K\\) observaciones del conjunto de entrenamiento más cercanas a \\(x_0\\), denotadas por \\(\\mathcal{N}_0\\). Entonces, se estima \\(f(x_0)\\) como el valor promedio de todas las respuestas contenidas en \\(\\mathcal{N}_0\\), es decir:\n\\[\n\\hat{f}(x_0) = \\frac{1}{K}\\sum_{x_i \\in \\mathcal{N}_0} \\,y_i.\n\\tag{3.1}\\]\n\n\n\n\n\n\nFigura 3.1: Valores estimados para una regresión KNN en un conjunto de datos en dos dimensiones con 64 observaciones. Izq.: K=1. Dcha.: K=9. Fuente: Fig. 3.16 (James, 2021).\n\n\n\nEste modelo se basa en la premisa de que las observaciones similares se encontrarán próximas entre sí dentro del espacio de representación de los datos. Sin embargo, no siempre es fácil encontrar espacios de representación que describan nuestro problema de forma adecuada para que se cumpla esta premisa. En todo caso, este modelo ha demostrado ser muy útil en gran variedad de problemas.\nEn la Sec. 8.2 de (Boehmke & Greenwell, 2019), se discuten algunas medidas de disimilaridad que se pueden computar entre pares de observaciones. Algunas funciones de distancia son la familia de distancias Minkowski, incluyendo Manhattan (L1), Euclídea (L2) o Chebyshev (Linf); la distancia de Haversine (para datos geolocalizados sobre la superficie terrestre); la similaridad del coseno (para documentos o datos textuales) o la distancia de Jaccard.\nEl modelo KNN para clasificación es muy directo. Sea \\(K\\) un número entero positivo y \\(x_0\\) una observación que deseamos clasificar. Primero, el algoritmo identifica las \\(K\\) observaciones más cercanas a \\(x_0\\), que denotamos por \\(\\mathcal{N}_0\\). Entonces, se estima la probabilidad condicional para la clase \\(j\\) como la fracción de puntos pertenecientes a \\(\\mathcal{N}_0\\) cuyos valores de respuesta son la clase \\(j\\). En otras palabras, se asigna la etiqueta de salida de la mayorí ade vecinos cercanos como la clase más probable para la salida a predecir para el punto \\(x_0\\):\n\\[\nP(Y=j \\mid X=x_0)= \\frac{1}{K}\\sum_{i \\in \\mathcal{N}_0} \\,I(y_i = j).\n\\tag{3.2}\\]\n\n3.2.1 Ajuste de un modelo de clasificación KNN\nEn el siguiente ejemplo se muestra cómo ajustar un modelo KNN para clasificación con el dataset mlbench::Sonar. La métrica que emplearemos para ajustar el hiperparámetro \\(K\\) es la curva ROC, presentada en la Sección 4.2.2.\n\nmodel_knn = train(Class ~ ., data=training, method='knn',\n                       metric=\"ROC\", trControl = config_control)\nmodel_knn\n\nk-Nearest Neighbors \n\n157 samples\n  9 predictor\n  2 classes: 'M', 'R' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 126, 126, 126, 125, 125 \nResampling results across tuning parameters:\n\n  k  ROC        Sens       Spec     \n  5  0.8092927  0.8213235  0.6733333\n  7  0.7894853  0.8213235  0.5895238\n  9  0.7808088  0.8095588  0.6285714\n\nROC was used to select the optimal model using the largest value.\nThe final value used for the model was k = 5.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html#sec-linear-models",
    "href": "03-algoritmos-modelos.html#sec-linear-models",
    "title": "3  Algoritmos y modelos",
    "section": "3.3 Modelos lineales",
    "text": "3.3 Modelos lineales\nLos modelos lineales asumen que existe una relación lineal entre las variables de entrada (inputs, features) y la salida que se desea predecir. Cuidado, porque esto no implica necesariamente que la forma de la función ajustada sea una línea recta, una confusión bastante común que suele asaltar a muchas personas.\nEl dos ejemplos muy básicos de este tipo de modelos son la regresión lineal simple y la regresión lineal múltiple, presentados en detalle en el Capítulo 4 de (Boehmke & Greenwell, 2019), así como en el Capítulo 3 de (James, 2021). Sin embargo, un polinomio de grado (parábola) sigue siendo un modelo lineal ya que, aunque su forma son sea una línea recta, la ecuación se sigue expresando como una combinación lineal de varias componentes.\nLos Modelos Lineales Generalizados (GLM por sus siglas en inglés) extienden el modelo lineal original para responder a muchos tipos de problemas: variables respuesta que no siguen una distribución normal, relaciones no lineales (no recta) entre las entradas y la variable de salida, o salidas de tipo categórico (binarias, multinomiales, ordenadas, etc.).\nEste tipo de modelos consta de tres elementos (Agresti, 2015):\n\nFunción de enlace: define una conexión entre el valor esperado (media) de la variable respuesta con la combinación lineal de las variables de entrada, lo que permite definir modelos que no sigan la forma de una recta (más flexibles), capturando relaciones más complejas.\nDistribución de probabilidad (componente aleatoria): describe el “ruido” o variabilidad de los datos alrededor del valor promedio que se predice. Distribuciones habituales son la Normal, Binomial o Poisson.\nEstructura lineal: todas las variables de entrada se relacionan entre sí mediante una combinación lineal, ponderadas por coeficientes que se ajustan a partir de los datos de entrenamiento. Sin embargo, la estructura generalizada del modelo permite asumir formas no lineales, así como incorporar variables de entrada categóricas, mediante la codificación adecuada.\n\nLa Tabla 3.3 presenta algunos modelos GLM frecuentemente empleados.\n\n\n\nTabla 3.3: Algunos modelos GLM y sus elementos constitutivos asociados.\n\n\n\n\n\n\n\n\n\n\nModelo\nComp. aleatoria\nCol3\n\n\n\n\nRegresión lineal\nNormal\nCuantitativas o cualitativas\n\n\nRegresión logística\nBinomial\nCuantitativas o cualitativas\n\n\nLogLinear\nPoisson\nCualitativas\n\n\nReg. de Poisson\nPoisson\nCuantitativas o cualitativas\n\n\n\n\n\n\n\n3.3.1 Ajuste de un modelo de clasificación LR\nSeguidamente, se presenta el proceso de ajuste y evaluación de un modelo de clasificación mediante regresión logística (LR). Este modelo estima una probabilidad a la salida y debemos establecer un umbral o threshold para dicha probabilidad estimada, a partir de cual (para valores superiores o iguales) asignamos una de las dos posibles etiquetas de salida (por ejemplo, 1). Para una probabilidad estimada menor que el umbral asignamos la otra posible etiqueta de salida (por ejemplo, 0).\n\n# Regresión logística\nmodel_glm &lt;- train(\n  Class ~ .,\n  data = training,\n  method = \"glm\",\n  metric = \"ROC\",\n  trControl = config_control\n)\nmodel_glm\n\nGeneralized Linear Model \n\n157 samples\n  9 predictor\n  2 classes: 'M', 'R' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 125, 126, 126, 125, 126 \nResampling results:\n\n  ROC        Sens       Spec     \n  0.8034314  0.7610294  0.7828571\n\n# Recuperamos los coeficientes del modelo final ajustado\nsummary(model_glm$finalModel)\n\n\nCall:\nNULL\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.4778     1.5031   1.648 0.099268 .  \nV1          -17.1009    12.1553  -1.407 0.159466    \nV11          -8.2378     2.3484  -3.508 0.000452 ***\nV17           2.3566     1.0500   2.244 0.024808 *  \nV23          -2.3698     1.0091  -2.348 0.018859 *  \nV28           0.4797     0.9750   0.492 0.622699    \nV34           2.0068     1.0909   1.840 0.065818 .  \nV40           3.3099     1.5339   2.158 0.030933 *  \nV45          -8.4562     2.1913  -3.859 0.000114 ***\nV56         -42.1597    42.1564  -1.000 0.317273    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 216.88  on 156  degrees of freedom\nResidual deviance: 144.85  on 147  degrees of freedom\nAIC: 164.85\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n3.3.2 Regularización en modelos lineales\nEn los conjuntos de datos actuales, normalmente de gran tamaño, existe el riesgo de que los modelos lineales tiendan al sobreajuste de los datos de entrenamiento, incrementando nuestro error de generalización. Una estrategia muy útil para restringir este efecto pernicioso es la regularización del modelo, que consiste en aplicar una serie de “penalizaciones” a los coeficientes estimados para reducir la varianza (dentro del compromiso varianza-sesgo) y así mantener a raya el problema del sobreajuste.\nTres opciones muy comunes de regularización son:\n\nPenalización Ridge: modifica la función objetivo de ajuste del modelo con un término controlado por un hiperparámetro \\(\\lambda\\). Cuanto más crece el valor asignado a \\(\\lambda\\) más se fuerza a que los coeficientes del modelo se vayan haciendo cada vez más pequeños, aunque sin llegar a anularse. Véase el Apartado 6.2.1 de (Boehmke & Greenwell, 2019).\nPenalización Lasso: altera la función objetivo para ajustar el modelo con un térmio también controlado por un hiperparámetro \\(\\lambda\\). Sin embargo, al contrario que en el caso anterior, cuando \\(\\lambda\\) crece se van anulando progresivamente más coeficientes de la función de predicción, lo que constituye un método más drástico de selección de variables y simplificación de nuestro modelo. Véase el Apartado 6.2.2 de (Boehmke & Greenwell, 2019).\nElastic net: es una solución intermedia entre los dos casos anteriores, introduciendo simultáneamente ambos tipos de penalización (Ridge y Lasso), cada uno de ellos controlado por un hiperparámetro de penalización, \\(\\lambda_1\\) y \\(\\lambda_2\\), respectivamente. Véase el Apartado 6.2.3 de (Boehmke & Greenwell, 2019).\n\nEn la Figura 3.2 se representan los errores (todos los puntos sobre una elipse tienen el mismo valor de RSS) y las funciones de restricción impuestas en el caso de la penalización Lasso y Ridge. Podemos observar como en el caso del Lasso las restricciones tienen aristas, lo que hace que la intersección entre el contorno y la región de restricción se produzca sobre el eje. Cuando esto ocurre, los coeficientes de la función de regresión se anulan. Sin embargo, en Ridge el punto de intersección no llega a tocar el eje, por lo que los coeficientes no llegan a anularse.\n\n\n\n\n\n\nFigura 3.2: Gráficos de contorno para los errores en las estimaciones y funciones de restricción para Lasso (izq.) y Ridge (dcha.). Fuente: Fig. 6.7 (James, 2021).",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html#extensiones-del-modelo-lineal",
    "href": "03-algoritmos-modelos.html#extensiones-del-modelo-lineal",
    "title": "3  Algoritmos y modelos",
    "section": "3.4 Extensiones del modelo lineal",
    "text": "3.4 Extensiones del modelo lineal\nAdemás de los modelos polinómicos o los GLM descritos anteriormente, existen más extensiones de los modelos lineales. La aproximación común a muchos de ellos es utilizar funciones polinómicas con formas suaves para ir ajustando tramos de la función de predicción. En consecuencia, la superposición (combinación lineal) de estas funciones suaves dará como resultado un modelo tremendamente flexible que se puede adaptar a problemas muy complicados.\nUn primer ejemplo son los modelos MARS (Multivariate Adaptive Regression Splines), presentados en el Capítulo 7 de (Boehmke & Greenwell, 2019). Otro ejemplo son los modelos GAM (Generalized Additive Models) que se explican en la Sección 7.7 de (James, 2021). En el caso de estos últimos se extiende el modelo lineal manteniendo la combinación aditiva (suma) de los componentes de predicción. Sin embargo, en cada componente se emplea una función lineal \\(f_j(x_{ij})\\), cuya forma debemos estimar a partir de los datos, según la Ecuación 3.3:\n\\[\ny_i = \\beta_0 + \\sum_{j=1}^{p}f_j(x_{ij})+\\epsilon_i\n\\tag{3.3}\\]\nLa Figura 3.3 muestra un ejemplo del resultado de ajustar un modelo GAM utilizando dos variables de entrada cuantitativas y una cualitativa.\n\n\n\n\n\n\nFigura 3.3: Ejemplo de ajuste de un modelo GAM, con dos predictores cuantitativos (izq. y centro) y otro cualitativo (dcha.). Se puede apreciar que las funciones para los predictores cuantiativos son flexibles y suaves. Fuente: Fig. 7.12 (James, 2021).\n\n\n\n\n3.4.1 Ajuste de un modelo GAM para clasificación\nLos modelos GAM pueden aplicarse tanto a problemas de regresión como de clasificación. En el paquete caret, podemos escoger ajustar un modelo de este tipo con el paquete mgcv o bien con el paquete gam.\nEn este caso, podremos ver que la función de enlace (link function) establecida para relacionar la salida con la combinación lineal de los regresores es logit.\n\nmodel_gam_mgcv = train(Class ~ ., data=training, method='gam',\n                  metric=\"ROC\", trControl = config_control)\nmodel_gam_mgcv\n\nGeneralized Additive Model using Splines \n\n157 samples\n  9 predictor\n  2 classes: 'M', 'R' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 125, 126, 126, 125, 126 \nResampling results across tuning parameters:\n\n  select  ROC        Sens       Spec     \n  FALSE   0.7728817  0.8095588  0.6171429\n   TRUE   0.7928011  0.7500000  0.7266667\n\nTuning parameter 'method' was held constant at a value of GCV.Cp\nROC was used to select the optimal model using the largest value.\nThe final values used for the model were select = TRUE and method = GCV.Cp.\n\nsummary(model_gam_mgcv$finalModel)\n\n\nFamily: binomial \nLink function: logit \n\nFormula:\n.outcome ~ s(V56) + s(V1) + s(V23) + s(V28) + s(V17) + s(V11) + \n    s(V34) + s(V40) + s(V45)\n\nParametric coefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)  -0.3515     0.2604   -1.35    0.177\n\nApproximate significance of smooth terms:\n          edf Ref.df Chi.sq  p-value    \ns(V56) 0.7416      9  1.815 0.108066    \ns(V1)  0.7876      9  2.435 0.071601 .  \ns(V23) 2.0615      9  7.979 0.009524 ** \ns(V28) 2.4275      9  7.407 0.020306 *  \ns(V17) 1.7828      9  6.784 0.013827 *  \ns(V11) 2.0751      9 16.218 5.11e-05 ***\ns(V34) 3.8758      9 10.983 0.012560 *  \ns(V40) 1.6428      9  3.822 0.074852 .  \ns(V45) 1.0000      9 14.341 0.000108 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.548   Deviance explained = 53.3%\nUBRE = -0.1328  Scale est. = 1         n = 157\n\n\n\nmodel_gam = train(Class ~ ., data=training, method='gamSpline',\n                  metric=\"ROC\", trControl = config_control)\nmodel_gam\n\nGeneralized Additive Model using Splines \n\n157 samples\n  9 predictor\n  2 classes: 'M', 'R' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 126, 125, 126, 125, 126 \nResampling results across tuning parameters:\n\n  df  ROC        Sens       Spec     \n  1   0.8047129  0.7639706  0.7295238\n  2   0.8616597  0.8110294  0.7961905\n  3   0.8607353  0.7992647  0.7676190\n\nROC was used to select the optimal model using the largest value.\nThe final value used for the model was df = 2.\n\ncoef(model_gam$finalModel)\n\n   (Intercept) s(V56, df = 2)  s(V1, df = 2) s(V23, df = 2) s(V28, df = 2) \n      2.174201     -53.809688     -17.909083      -2.124357       0.518643 \ns(V17, df = 2) s(V11, df = 2) s(V34, df = 2) s(V40, df = 2) s(V45, df = 2) \n      2.457338      -6.963477       2.165397       3.161222      -9.148652",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html#máquinas-de-vector-soporte-svm",
    "href": "03-algoritmos-modelos.html#máquinas-de-vector-soporte-svm",
    "title": "3  Algoritmos y modelos",
    "section": "3.5 Máquinas de vector soporte (SVM)",
    "text": "3.5 Máquinas de vector soporte (SVM)\nLas SVM son ejemplos de modelos de clasificación (salida cualitativa), en los que el objetivo es encontrar un hiperplano que separe de la mejor forma posible los elementos pertenecientes a dos grupos (asumiendo que la salida es una variable binaria).\nLa Figura 3.4 muestra cómo se identifican los llamados “vectores soporte” para definir la frontera de separación entre los puntos pertenecientes a los dos grupos de la variable de salida, para el caso de un clasficador de margen rígido (es decir, que no admite que puntos de uno de los grupos desborden la frontera con el otro grupo).\n\n\n\n\n\n\nFigura 3.4: Ilustración del método para encontrar los vectores soporte, que definen la frontera de separación entre los dos grupos de la variable de salida en un modelo SVM. Se asume un clasficador de margen rígido (HMC). Fuente: Fig. 14.3 (Boehmke & Greenwell, 2019).\n\n\n\nLo normal es utilizar una versión más flexible de este algoritmo, que tolera que existan puntos mal clasificados (i.e. en el lado incorrecto de la frontera), dentro de un cierto margen de error. No obstante, la verdadera clave de estos modelos es que aplican el llamado kernel trick, una argucia matemática que nos permite representar los datos en un espacio alternativo en el que la separación entre las fronteras sea calculable. Matemáticamente, entender esta herramienta implica el manejo de funciones núcleo (kernel functions) y comprender los Espacios de Hilbert de Núcleo Reproductor (RKHS). Puedes consultar estos apuntes de un profesor de UCL para una introducción a estos temas.\nEn la práctica, el hecho de que no podamos apreciar directamente los detalles del espacio alternativo en el que se están representando los datos hace que a estos modelos se les considere en cierta medida como de “caja negra” (black-box models). En consecuencia, otras de las limitaciones es que no resulta nada evidente explicar el papel que juega cada una de las variables en la identificación de la frontera de separación entre clases.\n\n\n\n\n\n\nFigura 3.5: Fronteras de separación entre dos grupos de datos que se organizan en forma de espiral. Izq.: frontera de clasificación determinada mediante un algoritmo RF. Dcha.: frontera de clasificación identificada mediante un algoritmo SVM que usa una función núcleo de base radial (radial basis kernel). Fuente: Fig. 14.7 (Boehmke & Greenwell, 2019).\n\n\n\n\n3.5.1 Ajuste de un modelo SVM (RBF)\nMostramos un ejemplo de cómo entrenar un modelo SVM, utilizando como función kernel la función de base radial (Radial Basis Function). Los hiperparámetros que controlan la complejidad del modelo son sigma y C.\n\nmodel_svmRadial = train(Class ~ ., data=training, method='svmRadial',\n                        metric=\"ROC\", tuneLength=15, trControl = config_control)\nmodel_svmRadial\n\nSupport Vector Machines with Radial Basis Function Kernel \n\n157 samples\n  9 predictor\n  2 classes: 'M', 'R' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 125, 125, 127, 125, 126 \nResampling results across tuning parameters:\n\n  C        ROC        Sens       Spec     \n     0.25  0.8440616  0.8441176  0.7104762\n     0.50  0.8624300  0.8316176  0.7095238\n     1.00  0.8698669  0.8323529  0.7371429\n     2.00  0.8789391  0.8198529  0.7514286\n     4.00  0.8760784  0.8198529  0.7390476\n     8.00  0.8634139  0.8198529  0.7657143\n    16.00  0.8351225  0.8198529  0.7257143\n    32.00  0.8435609  0.8080882  0.7123810\n    64.00  0.8480917  0.7705882  0.7266667\n   128.00  0.8480917  0.8308824  0.6990476\n   256.00  0.8480917  0.7955882  0.7123810\n   512.00  0.8480917  0.7955882  0.6990476\n  1024.00  0.8480917  0.7955882  0.6990476\n  2048.00  0.8480917  0.7838235  0.6980952\n  4096.00  0.8480917  0.8191176  0.6990476\n\nTuning parameter 'sigma' was held constant at a value of 0.07543981\nROC was used to select the optimal model using the largest value.\nThe final values used for the model were sigma = 0.07543981 and C = 2.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html#modelos-probabilísticos-naïve-bayes",
    "href": "03-algoritmos-modelos.html#modelos-probabilísticos-naïve-bayes",
    "title": "3  Algoritmos y modelos",
    "section": "3.6 Modelos probabilísticos: Naïve Bayes",
    "text": "3.6 Modelos probabilísticos: Naïve Bayes\nUn ejemplo de modelos de clasificación probabilísticos es el llamado Naïve Bayes (Bayes ingenuo), cuyo funcionamiento se basa en una aplicación directa del Teorema de Bayes. Se emplean con frecuencia en problemas de clasificación con datos textuales, cuando tenemos muchas variables de entrada o bien cuando el rango de valores de las variables de entrada es muy amplio.\nRecordemos que el Teorema de Bayes viene dado por:\n\\[\nP(B \\mid A) = \\frac{P(B)P(A \\mid B)}{P(A)}\n\\tag{3.4}\\]\nSi consideramos que las variables predictoras son independientes entre sí, entonces tenemos que la fórmula de predicción es:\n\\[\nP(Y_k \\mid X_1, \\dots, X_p) = \\frac{P(Y_k)\\prod_{j=1}^p P(X_j \\mid Y_k)}{P(X_1, X_2, \\dots, X_p)}\n\\tag{3.5}\\]\nPuesto que el denominador es una constante, nos centramos en calcular el valor del numerador para poder comparar las probabilidades condicionadas a los valores de las variables de entrada. La clase predicha maximiza la expresión:\n\\[\n\\underset{x}{\\arg\\max} \\left\\{ P(Y_k) \\prod_{j=1}^p P(X_j \\mid Y_k)\\right\\}.\n\\]",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html#redes-neuronales-y-aprendizaje-profundo",
    "href": "03-algoritmos-modelos.html#redes-neuronales-y-aprendizaje-profundo",
    "title": "3  Algoritmos y modelos",
    "section": "3.7 Redes neuronales y aprendizaje profundo",
    "text": "3.7 Redes neuronales y aprendizaje profundo\nMuchos modelos de aprendizaje automático solamente incorporan una o dos capas de transformación de datos para aprender la representación de los datos de salida. Estos modelos se denominan superficiales (shallow models). En contraste, los modelos profundos (deep models) siguen una aproximación multicapa para aprender las representaciones de los datos. El caso más habitual es el de usar múltiples capas de redes neuronales. El Capítulo 13 de (Boehmke & Greenwell, 2019) y el Capítulo 10 de (James, 2021) proporcionan dos buenas introducciones a este tipo de modelos.\nLa Figura 3.6 muestra el diseño de una red neuronal con dos capas ocultas que podría utilizarse para predecir los 10 posibles valores de salida del dataset MNIST, con imágenes de cifras manuscritas.\n\n\n\n\n\n\nFigura 3.6: Esquema de un modelo de clasificación basado en una red neuronal con dos capas ocultas y varias posibles salidas, que se puede aplicar al conjunto de datos MNIST de cifras manuscritas. Fuente: Fig. 10.4 (James, 2021).\n\n\n\nLa clave para que una red neuronal de aprendizaje profundo se autoajuste en base a los datos de entrenamiento es un proceso denominado retropropagación (backpropagation). Este proceso se explica, por ejemplo, en la Sec. 13.5 de (Boehmke & Greenwell, 2019), así como en la Sec. 10.7.1 de (James, 2021), entre otras muchas fuentes.\n\n\n\n\n\n\nVideotutorial sobre aprendizaje profundo\n\n\n\nEl sitio web https://www.3blue1brown.com/ contiene un extenso catálogo de videotutoriales y sesiones formativas sobrfe muchos temas de interés, como redes neuronales, álgebra o cálculo.\nEl vídeo What is backpropagation really doing? es una de las mejores explicaciones intuitivas para entender mejor el papel de la retropropagación en el entrenamiento de redes neuronales para aprendizaje profundo.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html#ensamblado-de-modelos",
    "href": "03-algoritmos-modelos.html#ensamblado-de-modelos",
    "title": "3  Algoritmos y modelos",
    "section": "3.8 Ensamblado de modelos",
    "text": "3.8 Ensamblado de modelos\nEl ensamblado de modelos es una aproximación para resolver el problema del aprendizaje máquina que consiste en combinar la salida de múltiples modelos individuales para dar una predicción final que mejora el rendimiento que podríamos alcanzar con un solo modelo. La referencia más completa para entender bien esta estrategia de aprendizaje máquina es (Kuncheva, 2014).\nAlgunos de los modelos más conocidos son:\n\nBagging (Bootstrap AGGregatING): consiste en el ensamblado de modelos de clasificación entrenados sobre réplicas bootstrap* de los datos de entrenamiento originales. La salida de los clasificadores individuales se combina mediante el voto de pluralidad. Utilizar el voto mayoritario para tomar la decisión garantiza que vamos a obtener un resultado que mejora el de cada modelo individual. El Capítulo 10 de (Boehmke & Greenwell, 2019) muestra en detalle ejemplos de esta técnica.\nRandom Forests (bosques aleatorios): fueron propuestos por el insigne Leo Breiman en 2001 (Breiman, 2001). Es una modificación de la estrategia de bagging aplicada a modelos de árboles de decisión, que emplea una amplia colección de árboles decorrelados entre sí para mejorar la eficiencia de predicción de la variable de salida. Además de tomar muestras bootstrap de los datos de entrenamiento, este método realiza selecciones aleatorias de las variables de entrada en cada nodo del árbol, tras lo cual se selecciona de entre las características tomadas la azar la mejor para dividir los caminos desde ese nodo. Es uno de los métodos más populares hoy en día, puesto que ofrece un buen rendimiento con un coste computacional contenido y con relativamente poco esfuerzo de ajuste de hiperparámetros. El Capítulo 11 de (Boehmke & Greenwell, 2019) muestra el trabajo con este tipo de algoritmos.\nBoosting: propone la construcción de un ensamblado de árboles poco profundos, secuencialmente, en el que cada árbol que se añade mejora al anterior. Aunque cada árbol poco profundo es una herramienta de aprendizaje débil, pueden ser “potenciados” (boosted) de este modo para crear un comité de modelos que ofrece un rendimiento muy bueno. Uno de los primeros métodos propuestos con esta estrategia fue AdaBoost. Una de las variantes más populares actualmente es XGBoost (Extreme Gradient Boosting) (véase Sec. 12.5 de (Boehmke & Greenwell, 2019)), que incluye hiperparámetros para controlar términos de penalización del modelo que reduzcan su complejidad y prevengan el sobreajuste.\n\n\n3.8.1 Ejemplo de ajuste de un modelo Random Forests (RF)\n\nmodel_rf = train(Class ~ ., data=training, method='rf',\n                 metric=\"ROC\", tuneLength=5, trControl = config_control)\nmodel_rf\n\nRandom Forest \n\n157 samples\n  9 predictor\n  2 classes: 'M', 'R' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 125, 127, 125, 126, 125 \nResampling results across tuning parameters:\n\n  mtry  ROC        Sens       Spec     \n  2     0.8592857  0.8330882  0.7942857\n  3     0.8732826  0.7970588  0.7809524\n  5     0.8693452  0.8323529  0.7809524\n  7     0.8782143  0.8323529  0.7942857\n  9     0.8717192  0.8088235  0.7800000\n\nROC was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 7.\n\n\n\n\n3.8.2 Ejemplo de ajuste de un modelo AdaBoost\n\nmodel_adaboost = train(Class ~ ., data=training, method='AdaBoost.M1',\n                       metric=\"ROC\", tuneLength=2, trControl = config_control)\nmodel_adaboost\n\nAdaBoost.M1 \n\n157 samples\n  9 predictor\n  2 classes: 'M', 'R' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 125, 126, 125, 126, 126 \nResampling results across tuning parameters:\n\n  coeflearn  maxdepth  mfinal  ROC        Sens       Spec     \n  Breiman    1          50     0.8149160  0.7735294  0.6571429\n  Breiman    1         100     0.8295518  0.7963235  0.7266667\n  Breiman    2          50     0.8341527  0.7852941  0.7400000\n  Breiman    2         100     0.8396429  0.7970588  0.7257143\n  Freund     1          50     0.8370448  0.7852941  0.7247619\n  Freund     1         100     0.8375700  0.7970588  0.7523810\n  Freund     2          50     0.8490966  0.7500000  0.7114286\n  Freund     2         100     0.8391246  0.7970588  0.6980952\n  Zhu        1          50     0.8489286  0.7375000  0.7390476\n  Zhu        1         100     0.8407633  0.7382353  0.7390476\n  Zhu        2          50     0.8560364  0.8102941  0.7523810\n  Zhu        2         100     0.8264146  0.7742647  0.7228571\n\nROC was used to select the optimal model using the largest value.\nThe final values used for the model were mfinal = 50, maxdepth = 2\n and coeflearn = Zhu.\n\n\n\n\n3.8.3 Ejemplo de ajuste de modelos XGBoost\nXGBoost lineal\n\nmodel_xgbLinear = train(Class ~ ., data=training, method='xgbLinear',\n                        metric=\"ROC\", tuneLength=5, trControl = config_control, verbose=F)\n# Descomentar para ver iteraciones\n# model_xgbLinear\n\n\nstopCluster(cl)",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "03-algoritmos-modelos.html#apilado-de-modelos",
    "href": "03-algoritmos-modelos.html#apilado-de-modelos",
    "title": "3  Algoritmos y modelos",
    "section": "3.9 Apilado de modelos",
    "text": "3.9 Apilado de modelos\nPor último, otra posible estrategia de combinación de modelos de aprendizaje individuales es el apilado de modelos (model stacking), que implica el entrenamiento de un nuevo modelo que combina las predicciones de varios modelos de aprendizaje de base. El meta-algoritmo que combina las salidas previas, llamado super learner permite mejorar aún más el rendimiento de los modelos de aprendizaje de base (como RF o XGBoost). En el Capítulo 15 de (Boehmke & Greenwell, 2019) se puede encontrar más información y ejemplos de este tipo de modelos.\n\n\n\n\nAgresti, A. (2015). Foundations of Linear and Generalized Linear Models (1.ª ed.). John Wiley & Sons.\n\n\nBlake, C. L., & Merz, C. J. (1998). UCI Repository of Machine Learning Databases. University of California, Irvine, Department of Information; Computer Sciences.\n\n\nBoehmke, B., & Greenwell, B. (2019). Hands-On Machine Learning with R (1.ª ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBreiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.\n\n\nGorman, R. P., & Sejnowski, T. J. (1988). Analysis of Hidden Units in a Layered Network Trained to Classify Sonar Targets. Neural Networks, 1, 75-89. https://doi.org/10.1016/0893-6080(88)90023\n\n\nJames, W., G. (2021). An Introduction to Statistical Learning with Applications in R (2.ª ed.). Springer. https://www.statlearning.com/\n\n\nKuncheva, L. I. (2014). Combining Pattern Classifiers: Methods and Algorithms (2.ª ed.). Wiley-Interscience. https://lucykuncheva.co.uk/Combining_Pattern_Classifiers_Methods_and_Algorithms_2nd_ed_Kuncheva%202014-09-09.pdf\n\n\nLeisch, F., & Dimitriadou, E. (2024). mlbench: Machine Learning Benchmark Problems. https://CRAN.R-project.org/package=mlbench",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algoritmos y modelos</span>"
    ]
  },
  {
    "objectID": "04-seleccion-validacion.html",
    "href": "04-seleccion-validacion.html",
    "title": "4  Selección y validación de modelos",
    "section": "",
    "text": "4.1 Consideraciones generales\nHace varias décadas, la evaluación y selección de modelos se efectuaba mediante pruebas estadísticas que medían la bondad de los ajustes y a través de la evaluación de los residuos (errores) del modelo propuesto. Hoy en días, la evaluación se realiza empleando medios mucho más robustos, las conocidas como funciones de pérdida (loss functions).\nUna función de pérdida es una métrica que compara los valores predichos respecto de los valores que realmente se han producido. Su salida se denomina habitualmente error o bien pseudo-residuo. En este contexto, tenemos que tener en cuenta una premisa fundamental:\n\\[\n\\text{DATOS} = \\text{MODELO} + \\text{ERROR}.\n\\]\nExisten muchos tipos de funciones de pérdida para evaluar el rendimiento de modelos predictivos, cada una con sus ventajas e inconvenientes. Es importante recordar que cada función de pérdida se calcula teniendo en cuenta uno o varios tipos de error cometidos por el modelo, dejando otros de lado, por lo que es complicado afirmar mirando una sola de estas funciones que podemos escoger un modelo óptimo. Dependiendo del problema en cuestión, debemos seleccionar primero la función o funciones de pérdida más adecuadas para evaluar las características del modelo que nos interesan. Después, podemos aplicarlas para evaluar los candidatos y seleccionar una opción.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección y validación de modelos</span>"
    ]
  },
  {
    "objectID": "04-seleccion-validacion.html#consideraciones-generales",
    "href": "04-seleccion-validacion.html#consideraciones-generales",
    "title": "4  Selección y validación de modelos",
    "section": "",
    "text": "Los datos describen la realidad que queremos explicar mediante el modelo, a través de una serie de variables que describen dicho problema.\nEl modelo es una representación simplificada de la realidad, propuesta para intentar describirla de manera más fácilmente comprensible. Cuanto más sencillo sea el modelo más fácil será interpretarlo, pero también puede que cometa más imprecisiones al describir el fenómeno real que estudiamos.\nEl error representa el fallo que cometemos al simplificar la realidad mediante el modelo simplificado.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección y validación de modelos</span>"
    ]
  },
  {
    "objectID": "04-seleccion-validacion.html#métricas-de-rendimiento",
    "href": "04-seleccion-validacion.html#métricas-de-rendimiento",
    "title": "4  Selección y validación de modelos",
    "section": "4.2 Métricas de rendimiento",
    "text": "4.2 Métricas de rendimiento\n\n4.2.1 Modelos de regresión\n\nError Cuadrático Medio (Mean Squared Error o MSE): el objetivo es minimizar el promedio de la combinación de los errores cuadráticos cometidos en la predicción de cada punto.\n\n\\[\n\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n\\tag{4.1}\\]\nHay que tener en cuenta que en modelos de regresión lineal, el divisor de la ecuación Ecuación 4.1 es \\(n-p\\) para proporcionar una mejor estimación (reduciendo el sesgo).\n\nRaíz del Error Cuadrático Medio (Root Mean Squared Error o RMSE): es la raíz cuadrada del MSE. Su fin es dar una estimación del error cometido en las mismas unidades que la variable de salida que buscamos predecir. El objetivo aquí también es minimizar la función de pérdida.\nDesviación: desviación promedio de los residuos, cuando el modelo se estima mediante un método de máxima verosimilitud. Se suele emplear en modelos de clasificación y el objetivo es minimizar su valor.\nError Medio Absoluto (Mean Absolute Error o MAE): en este caso, en lugar de tomar la raíz cuadrada del MSE se calculan las diferencias entre los valores reales y predichos tomando su valor absoluto, lo que contiene la influencia de los errores con valores altos. EL objetivo es minimizar la función de pérdida.\nError Medio Cuadrático Logarítmico (*Root Mean Squared Logarithmic Error** o RMSLE): Es la raíz cuadrada del error medio cuadrático logarítmico. Permite que los errores grandes cometidos sobre valores de salida de magnitud pequeña contribuyan de igual forma a la función de pérdida que los errores grandes cometidos sobre valores de salida de magnitud grande, ya que de otro modo los segundos prevalecerían sobre los primeros. Aquí el objetivo es minimizar igualmente la función de pérdida.\n\n\\[\n\\text{RMSLE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (log(y_i +1) -  log(\\hat{y}_i + 1))^2}.\n\\tag{4.2}\\]\n\n\\(R^2\\) y \\(R_{adj}^2\\): son métricas que representan el porcentaje de la varianza total de los datos que el modelo es capaz de explicar. La versión ajustada intenta tener en cuenta el número de variables predictoras empleadas, penalizando modelos más complejos. De otro modo, usar un mayor número de variables normalmente aumentaría sin más el valor de \\(R^2\\). El objetivo aquí es maximizar su valor. No obstante, es preciso obrar con precaución puesto que, como se indica en (Boehmke & Greenwell, 2019) (Sec. 2.6.2), dos modelos entrenados con datos diferentes que tengan el mismo RMSE, pero en los que el primero tenga menos variabilidad (dispersión) en los valores de la salida del modelo que el segundo tendrá también un \\(R^2\\) menor.\n\n\n\n4.2.2 Modelos de clasificación\nLas métricas de rendimiento de los modelos de clasificación se suelen construir a partir de los valores de la llamada matriz de confusión, que refleja el tipo de aciertos y errores cometidos por el modelo al clasificar, como muesgtra la Figura 4.1.\n\n\n\n\n\n\nFigura 4.1: Representación de los diferentes tipos de aciertos y errores que refleja la matriz de confusión y el nombre que suelen recibir en evaluación de modelos de clasificación. Fuente: Fig. 2.12 (Boehmke & Greenwell, 2019).\n\n\n\n\nAccuracy: se define como (objetivo: maximizar)\n\n\\[\n\\text{ACC} = \\frac{\\text{TP}+\\text{TN}}{\\text{total}}.\n\\tag{4.3}\\]\n\nPrecision: se define como (objetivo: maximizar)\n\n\\[\n\\text{PREC} = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}}.\n\\tag{4.4}\\]\n\nRecall (sensitivity): se define como (objetivo: maximizar)\n\n\\[\n\\text{RECALL}= \\frac{\\text{TP}}{\\text{TP}+\\text{FN}}.\n\\tag{4.5}\\]\n\nSpecificity: se define como (objetivo: maximizar)\n\n\\[\n\\text{SPEC}=\\frac{\\text{TN}}{\\text{TN}+\\text{FP}}.\n\\tag{4.6}\\]\n\nF1-score: se trata de la media armónica entre precisión y recall, dado por\n\n\\[\n\\text{F1} = 2\\;\\frac{\\text{PREC}\\times\\text{RECALL}}{\\text{PREC} + \\text{RECALL}}\n\\tag{4.7}\\]\n\nF-score generalizado: como el anterior, pero añadiendo pesos de ponderación, dado por\n\n\\[\n\\text{F1} = (1+\\beta^2)\\;\\frac{\\text{PREC}\\times\\text{RECALL}}{\\beta^2\\text{PREC} + \\text{RECALL}}\n\\tag{4.8}\\]\nSi \\(\\beta=1\\) tenemos el F1-score. Si \\(\\beta=2\\) otorgamos el doble de peso a la recuperación frente a la precisión y al contrario si \\(\\beta=0.5\\).\n\nAUC (Área Bajo la Curva ROC): dependiendo de los valores otorgados a los hiperparámetros del modelo, podremos mejorar la precisión, la sensitividad o ambas, minimizando los falsos positivos y falsos negativos. Las curvas ROC (Receiver Operating Characteristic) se crearon para represntar gráficamente estos valores en función de cada combinación de los hiperparámetros del modelo, permitiendo una evaluación gráfica más general de su rendimiento. En este caso el Area Under the [ROC] Curve (concretamente, entre la curva ROC y la línea recta diagonal que representa a un clasificador aleatorio) debe ser lo más grande posible. Estos conceptos se muestran en la\n\n\n\n\n\n\n\n\n\n\nFigura 4.2: Representación de varias curvas ROC y su interpretación en evaluación de modelos de clasificación. Fuente: Fig. 2.14 (Boehmke & Greenwell, 2019).\n\n\n\nAdemás de estas métricas, habituales en modelos de clasificación, podemos considerar otras posibles funciones de pérdida.\n\nError de clasificación: Es el error promedio total, que buscamos minimizar. Por ejemplo, asumamos tenemos que clasificar la salida en dos posibles grupos y cada uno consta de 40 observaciones. Si fallamos al clasificar 6 elementos del primer grupo y 3 del segundo, en total hemos fallado en 9 de las 40 observaciones, lo que implica un ratio de clasificación incorrecta del 11,25%.\nError promedio por clase: Este es el error promedio cometido dentro de cada clase. Por ejemplo, en el problema anterior sería \\(6/40\\) en el primer grupo y \\(3/40\\) en el segundo grupo. El propósito es minimizar este error.\nEntropía cruzada (cross-entropy o Log Loss o deviance): esta métrica penaliza en gran medida los casos en los que se asigna una alta probabilidad a una salida incorrecta (es decir, el modelo se dice muy seguro de la respuesta, pero ha fallado). El objetivo también es minimizar su valor.\nÍndice de Gini: empleado en modelos basados en árboles de decisión, es una medida de pureza (purity), donde valores pequeños indican que un nodo contiene, de forma predominante, observaciones de una sola clase. Por tanto, permite medir lo bien que es capaz de separar las clases entre sí el árbol en cada nodo. El objetivo es minimizar su valor.\n\n\n\n4.2.3 Ajuste de parámetros\nComo se ha explicado en la Sección 2.4, cuando escogemos una o varias métricas de evaluación de rendimiento, el procedimiento que solemos seguir es aplicar un método de validación (cruzada con \\(k\\) conjuntos, bootstrapping) para obtener un resultado de evaluación en cada iteración. Finalmente, se combinan estos resultados para obtener una evaluación final de cada modelo, así como unos valores adecuados con los que fijar los hiperparámetros necesarios del modelo.\nEn el caso de los modelos de regresión (salida numérica), este proceso es bastante directo, comparando los resultados de la métrica o métricas seleccionadas. Sin embargo, en el caso de modelos de clasificación la evaluación es más complicada, porque como hemos visto hay que tener en cuenta el rendimiento del modelo para cada uno de los posibles grupos o clases presentes en la variable de salida. Por ese motivo, y debido al hecho de que diferentes combinaciones de los hiperparámetros del modelo ofrecen resultados distintos para la sensibilidad y la especificidad, se prefiere optar por comparar modelos mediante las curvas ROC.\nEn ciertas ocasiones, valdrá la pena, si tenemos tiempo y suficientes recursos computacionales a nuestra disposición, realizar una búsqueda sistemática de los posibles valores de los hiperparámetros de nuestro modelo para garantizar nuestra selección. Esta búsqueda sistemática o grid search implica definir un rango de posibles valores entre los cuales realizaremos un “barrido”, comparando los resultados obtenidos para intentar conseguir un resultado adecuado.",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección y validación de modelos</span>"
    ]
  },
  {
    "objectID": "04-seleccion-validacion.html#comparación-de-modelos",
    "href": "04-seleccion-validacion.html#comparación-de-modelos",
    "title": "4  Selección y validación de modelos",
    "section": "4.3 Comparación de modelos",
    "text": "4.3 Comparación de modelos\n\n4.3.1 Curvas ROC\nLa Figura 4.3 representa gráficamente el llamado ROC convex hull (ROCCH) Fawcett & Provost (2001), que colorea en gris un área cuyo perímetro exterior corresponde a puntos que tienen el mismo rendimiento de clasificaión, desde el punto de vista de la curva ROC.\n\n\n\n\n\n\nFigura 4.3: Representación del convex hull bajo varias curvas ROC, que determina posibles clasificadores óptimos para un problema dado, en función de las restricciones y prioridades consideradas. Fuente: Fig. 7 (Fawcett, 2006).\n\n\n\nPor ejemplo, en la Figura 4.3 a) (izq.) podemos ver que las curvas B y D están dentro de la región del convex hull y, por tanto, son subóptimas para cualquier condición. Por contra, el área principal del convex hull queda delimitada por partes de las curvas A y C. Por lo tanto, si buscamos un clasificador óptimo podríamos eliminar B y D del proceso de selección, directamente. También podemos descartar la utilización de cualquier configuración de los modelos A y C cuyo rendimiento no se encuentre sobre el perímetro del convex hull.\nMatemáticamente, dos puntos en el espacio ROC, \\((FP_1, TP_1)\\) y \\((FP_2, TP_2)\\) tienen un rendimiento equivalente desde el punto de vista de la curva ROC si:\n\\[\n\\frac{TP_2 - TP_1}{FP_2 - FP_1} = m\\,.\n\\]\nEn la Figura 4.3 b) (dcha.), se representan dos líneas explícitasa con rendimiento uniforme, \\(\\alpha\\) y \\(\\beta\\).\nConsideremos un típico problema de clasificación binaria, con dos posibles clases de salida \\(\\{-1, 1\\}\\). En un primer escenario de clasificaión, en el que la clase negativa sobrepasa en número 10:1 a la clase positiva, pero los falsos negativos (FN) y los falsos positivos (FP) tienen el mismo coste, el resultado sería \\(m = 10\\). La línea con pendiente \\(m = 10\\) mas al noroeste (esquina superior izq., mejor rendimiento) del la gráfica ROC es \\(\\alpha\\), tangente al clasificador A. Ese sería el clasificador selecciónado.\nSi ahora tenemos otro escenario de clasificación, en el que la clase negativa y la positiva están balanceadas en número de observaciones, pero un FN es 10 veces más costoso que un FP, entonces el resultado de la ecuación anterior sería \\(m=1/10\\). La curva más al noroeste de la gráfica ROC con esa pendiente es \\(\\beta\\), tangente al clasificador C. Por tanto, ese sería el clasificador más adecuado para este escenario (Fawcett, 2006). En consecuencia, no es inmediato determinar qué clasificador es mejor o peor en términos absolutos, puesto que es imprescindible tener en cuenta las condiciones de contorno del problema (balance de observaciones entre clases, coste de cada error de clasificación, etc.).\nUna forma muy habitual de reducir la información de la curva ROC es calcular el AUC, que hemos definido más arriba. Esta métrica tiene una propiedad interesante: el AUC de un clasificador es equivalente a la probabilidad de que el clasificador asigne un ranking mayor a una instancia positiva elegida al azar que a una instancia negativa elegida también al azar. Por otro lado, el AUC también está relacionado con el coeficiente de Gini (Hand, 2001): \\(\\text{Gini} + 1 = 2 \\times \\text{AUC}\\).\n\n\n4.3.2 Comparación de modelos con R\nVeamos ahora cómo comparar los modelos que hemos ajustado en los ejemplos del Capítulo 3, usando el paquete caret.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\nlibrary(caret)\nlibrary(doParallel)\nlibrary(mlbench)\n\ncl &lt;- makePSOCKcluster(5) # 5 cores para proc. paralelo\nregisterDoParallel(cl)\n\n\nload(\"data/sonar-models.RData\")\n\n# Compare model performances using resample()\nmodels_compare &lt;- resamples(list(GLM=model_glm, ADABOOST=model_adaboost, KNN=model_knn,\n                                 XGBOOST=model_xgbLinear, RF=model_rf, GAM_MGCV=model_gam_mgcv, \n                                 GAM_GAM=model_gam, SVM=model_svmRadial))\n\n# Summary of the models performances\nsummary(models_compare)\n\n\nCall:\nsummary.resamples(object = models_compare)\n\nModels: GLM, ADABOOST, KNN, XGBOOST, RF, GAM_MGCV, GAM_GAM, SVM \nNumber of resamples: 5 \n\nROC \n              Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nGLM      0.7773109 0.7921569 0.8109244 0.8034314 0.8117647 0.8250000    0\nADABOOST 0.7916667 0.8529412 0.8705882 0.8560364 0.8784314 0.8865546    0\nKNN      0.7773109 0.7875000 0.8078431 0.8092927 0.8130252 0.8607843    0\nXGBOOST  0.8039216 0.8541667 0.8781513 0.8780602 0.9254902 0.9285714    0\nRF       0.7767857 0.8509804 0.8588235 0.8782143 0.9201681 0.9843137    0\nGAM_MGCV 0.7000000 0.7352941 0.7836134 0.7928011 0.8666667 0.8784314    0\nGAM_GAM  0.6974790 0.8705882 0.8791667 0.8616597 0.8862745 0.9747899    0\nSVM      0.7812500 0.8487395 0.8784314 0.8789391 0.8941176 0.9921569    0\n\nSens \n              Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nGLM      0.6875000 0.7058824 0.7058824 0.7610294 0.8235294 0.8823529    0\nADABOOST 0.7058824 0.7647059 0.8235294 0.8102941 0.8750000 0.8823529    0\nKNN      0.7058824 0.8125000 0.8235294 0.8213235 0.8823529 0.8823529    0\nXGBOOST  0.6875000 0.7647059 0.8235294 0.7963235 0.8235294 0.8823529    0\nRF       0.7058824 0.7500000 0.8235294 0.8323529 0.8823529 1.0000000    0\nGAM_MGCV 0.6470588 0.7500000 0.7647059 0.7500000 0.7647059 0.8235294    0\nGAM_GAM  0.6470588 0.7647059 0.8235294 0.8110294 0.8823529 0.9375000    0\nSVM      0.6875000 0.7647059 0.8235294 0.8198529 0.8823529 0.9411765    0\n\nSpec \n              Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nGLM      0.6000000 0.7333333 0.7857143 0.7828571 0.8666667 0.9285714    0\nADABOOST 0.6428571 0.6666667 0.7857143 0.7523810 0.8000000 0.8666667    0\nKNN      0.5333333 0.5333333 0.7142857 0.6733333 0.7857143 0.8000000    0\nXGBOOST  0.6666667 0.7142857 0.7333333 0.7542857 0.8000000 0.8571429    0\nRF       0.6428571 0.6666667 0.8000000 0.7942857 0.9285714 0.9333333    0\nGAM_MGCV 0.4666667 0.7142857 0.7857143 0.7266667 0.8000000 0.8666667    0\nGAM_GAM  0.6666667 0.7142857 0.7333333 0.7961905 0.8666667 1.0000000    0\nSVM      0.5714286 0.6000000 0.7857143 0.7514286 0.8000000 1.0000000    0\n\n\n\n# Draw box plots to compare models\nscales &lt;- list(x=list(relation=\"free\"), y=list(relation=\"free\"))\nbwplot(models_compare, scales=scales)\n\n\n\n\n\n\n\nFigura 4.4: Comparación gráfica del rendimiento de varios modelos de clasificación candidatos para el problema del dataset mlbench::Sonar. Fuente: [kuhn2013applied].\n\n\n\n\n\nAnálogamente, el paquete caret también incluye funciones que permiten analizar estadísticamente las diferencias entre los modelos, tal y como se explica en la Sec. 5.8.2 del manual de paquete.\n\nstopCluster(cl)\n\n\n\n\n\nBoehmke, B., & Greenwell, B. (2019). Hands-On Machine Learning with R (1.ª ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nFawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27(8), 861-874. https://doi.org/10.1016/j.patrec.2005.10.010\n\n\nFawcett, T., & Provost, F. (2001). Robust Classification for Imprecise Environments. Machine Learning, 42, 203-231. https://doi.org/10.1023/A:1007601015854\n\n\nHand, T., D. J. (2001). A simple generalization of the area under the ROC curve to multiple class classification problems. Machine Learning, 45(2), 171-186. https://doi.org/10.1023/A:1010920819831",
    "crumbs": [
      "Fundamentos",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección y validación de modelos</span>"
    ]
  },
  {
    "objectID": "05-modelos-clasicos.html",
    "href": "05-modelos-clasicos.html",
    "title": "5  Modelos clásicos",
    "section": "",
    "text": "5.1 K vecinos más cercanos (k-NN)\nThis is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.",
    "crumbs": [
      "Métodos convencionales",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos clásicos</span>"
    ]
  },
  {
    "objectID": "05-modelos-clasicos.html#modelos-lineales",
    "href": "05-modelos-clasicos.html#modelos-lineales",
    "title": "5  Modelos clásicos",
    "section": "5.2 Modelos lineales",
    "text": "5.2 Modelos lineales",
    "crumbs": [
      "Métodos convencionales",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos clásicos</span>"
    ]
  },
  {
    "objectID": "05-modelos-clasicos.html#máquinas-de-vector-soporte-svm",
    "href": "05-modelos-clasicos.html#máquinas-de-vector-soporte-svm",
    "title": "5  Modelos clásicos",
    "section": "5.3 Máquinas de vector soporte (SVM)",
    "text": "5.3 Máquinas de vector soporte (SVM)",
    "crumbs": [
      "Métodos convencionales",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos clásicos</span>"
    ]
  },
  {
    "objectID": "05-modelos-clasicos.html#modelos-probabilísticos-naïve-bayes",
    "href": "05-modelos-clasicos.html#modelos-probabilísticos-naïve-bayes",
    "title": "5  Modelos clásicos",
    "section": "5.4 Modelos probabilísticos: Naïve Bayes",
    "text": "5.4 Modelos probabilísticos: Naïve Bayes",
    "crumbs": [
      "Métodos convencionales",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos clásicos</span>"
    ]
  },
  {
    "objectID": "05-modelos-clasicos.html#random-forests",
    "href": "05-modelos-clasicos.html#random-forests",
    "title": "5  Modelos clásicos",
    "section": "5.5 Random Forests",
    "text": "5.5 Random Forests\n\n\n\n\nKnuth, D. E. (1984). Literate Programming. Comput. J., 27(2), 97-111. https://doi.org/10.1093/comjnl/27.2.97",
    "crumbs": [
      "Métodos convencionales",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos clásicos</span>"
    ]
  },
  {
    "objectID": "06-modelos-avanzados.html",
    "href": "06-modelos-avanzados.html",
    "title": "6  Modelos avanzados",
    "section": "",
    "text": "6.1 Gradient Boosting",
    "crumbs": [
      "Métodos convencionales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos avanzados</span>"
    ]
  },
  {
    "objectID": "06-modelos-avanzados.html#aprendizaje-profundo",
    "href": "06-modelos-avanzados.html#aprendizaje-profundo",
    "title": "6  Modelos avanzados",
    "section": "6.2 Aprendizaje profundo",
    "text": "6.2 Aprendizaje profundo",
    "crumbs": [
      "Métodos convencionales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos avanzados</span>"
    ]
  },
  {
    "objectID": "06-modelos-avanzados.html#mixturas-gaussianas",
    "href": "06-modelos-avanzados.html#mixturas-gaussianas",
    "title": "6  Modelos avanzados",
    "section": "6.3 Mixturas Gaussianas",
    "text": "6.3 Mixturas Gaussianas",
    "crumbs": [
      "Métodos convencionales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos avanzados</span>"
    ]
  },
  {
    "objectID": "07-tidymodels.html",
    "href": "07-tidymodels.html",
    "title": "7  Tidymodels",
    "section": "",
    "text": "7.1 Flujo de trabajo con Tidymodels",
    "crumbs": [
      "Tidymodels",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Tidymodels</span>"
    ]
  },
  {
    "objectID": "07-tidymodels.html#otro-paquete",
    "href": "07-tidymodels.html#otro-paquete",
    "title": "7  Tidymodels",
    "section": "7.2 Otro paquete",
    "text": "7.2 Otro paquete",
    "crumbs": [
      "Tidymodels",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Tidymodels</span>"
    ]
  },
  {
    "objectID": "07-tidymodels.html#preparación-de-datos-con-recipes",
    "href": "07-tidymodels.html#preparación-de-datos-con-recipes",
    "title": "7  Tidymodels",
    "section": "7.3 Preparación de datos con recipes",
    "text": "7.3 Preparación de datos con recipes",
    "crumbs": [
      "Tidymodels",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Tidymodels</span>"
    ]
  },
  {
    "objectID": "07-tidymodels.html#ajuste-de-modelos-con",
    "href": "07-tidymodels.html#ajuste-de-modelos-con",
    "title": "7  Tidymodels",
    "section": "7.4 Ajuste de modelos con…",
    "text": "7.4 Ajuste de modelos con…",
    "crumbs": [
      "Tidymodels",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Tidymodels</span>"
    ]
  },
  {
    "objectID": "07-tidymodels.html#evaluación-de-modelos-con-yardstick",
    "href": "07-tidymodels.html#evaluación-de-modelos-con-yardstick",
    "title": "7  Tidymodels",
    "section": "7.5 Evaluación de modelos con yardstick",
    "text": "7.5 Evaluación de modelos con yardstick",
    "crumbs": [
      "Tidymodels",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Tidymodels</span>"
    ]
  },
  {
    "objectID": "08-mlr3.html",
    "href": "08-mlr3.html",
    "title": "8  MLR3",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, D. E. (1984). Literate Programming. Comput. J., 27(2), 97-111. https://doi.org/10.1093/comjnl/27.2.97",
    "crumbs": [
      "Otros entornos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>MLR3</span>"
    ]
  },
  {
    "objectID": "09-add-resources.html",
    "href": "09-add-resources.html",
    "title": "9  Recursos adicionales",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, D. E. (1984). Literate Programming. Comput. J., 27(2), 97-111. https://doi.org/10.1093/comjnl/27.2.97",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Recursos adicionales</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Agresti, A. (2015). Foundations of Linear and\nGeneralized Linear Models (1st ed.). John Wiley & Sons.\n\n\nBoehmke, B., & Greenwell, B. (2019). Hands-on machine learning\nwith r (1st ed.). Chapman; Hall/CRC. https://doi.org/10.1201/9780367816377\n\n\nBreiman, L. (2001). Random forests. Machine Learning,\n45(1), 5–32.\n\n\nDe Cock, D. (2011). Ames, iowa: Alternative to the boston housing data\nas an end of semester regression project. Journal of Statistics\nEducation, 19(3). https://doi.org/10.1080/10691898.2011.11889627\n\n\nEfron, B., & Tibshirani, R. J. (1993). Bootstrap Methods and Their Application.\nChapman; Hall/CRC.\n\n\nFawcett, T. (2006). An introduction to ROC analysis. Pattern\nRecognition Letters, 27(8), 861–874. https://doi.org/10.1016/j.patrec.2005.10.010\n\n\nGorman, R. P., & Sejnowski, T. J. (1988). Analysis of hidden units\nin a layered network trained to classify sonar targets. Neural\nNetworks, 1, 75–89. https://doi.org/10.1016/0893-6080(88)90023\n\n\nGrigorev, A. (2021). Machine learning bookcamp (1st ed.).\nManning Publications Co. https://www.manning.com/books/machine-learning-bookcamp\n\n\nHand, T., D. J. (2001). A simple generalization of the area under the\nROC curve to multiple class classification problems. Machine\nLearning, 45(2), 171–186. https://doi.org/10.1023/A:1010920819831\n\n\nHyndman, R. J., & Athanasopoulos, G. (2021). Forecasting: Principles and Practice (3rd\ned.). OTexts. https://otexts.com/fpp3/\n\n\nJames, W., G. (2021). An Introduction to\nStatistical Learning with Applications in R (2nd ed.).\nSpringer. https://www.statlearning.com/\n\n\nKnuth, D. E. (1984). Literate programming. Comput. J.,\n27(2), 97–111. https://doi.org/10.1093/comjnl/27.2.97\n\n\nKuhn, M. (2020). AmesHousing: The ames iowa housing data. https://doi.org/10.32614/CRAN.package.AmesHousing\n\n\nKuhn, M., & Johnson, K. (2013). Applied Predictive\nModeling. Springer New York. https://books.google.es/books?id=xYRDAAAAQBAJ\n\n\nKuhn, M., & Johnson, K. (2019). Feature\nEngineering and Selection: A Practical Approach for Predictive\nModels. Chapman & Hall/CRC. http://www.feat.engineering/\n\n\nKuncheva, L. I. (2014). Combining pattern classifiers: Methods and\nalgorithms (2nd ed.). Wiley-Interscience. https://lucykuncheva.co.uk/Combining_Pattern_Classifiers_Methods_and_Algorithms_2nd_ed_Kuncheva%202014-09-09.pdf\n\n\nLeisch, F., & Dimitriadou, E. (2024). Mlbench: Machine learning\nbenchmark problems. https://CRAN.R-project.org/package=mlbench\n\n\nRaschka, S. (2020). Model evaluation, model selection, and algorithm\nselection in machine learning. https://arxiv.org/abs/1811.12808\n\n\nRussell, S., & Norvig, P. (2009). Artificial intelligence: A\nmodern approach (3rd ed.). Prentice Hall Press.\n\n\nWolpert, D. H. (1996). The lack of a priori distinctions between\nlearning algorithms. Neural Computation, 8(7),\n1341–1390. https://doi.org/10.1162/neco.1996.8.7.1341\n\n\nZheng, A., & Casari, A. (2018). FFeature\nEngineering for Machine Learning: Principles and Techniques for Data\nScientists. O’Reilly Media, Inc. https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/",
    "crumbs": [
      "Referencias"
    ]
  }
]