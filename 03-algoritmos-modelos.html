<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Algoritmos y modelos – Aprendizaje máquina supervisado con R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04-seleccion-validacion.html" rel="next">
<link href="./02-ml-supervisado.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-04e1f1103201cc0a83f720091ef4aae4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-introduccion.html">Fundamentos</a></li><li class="breadcrumb-item"><a href="./03-algoritmos-modelos.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Algoritmos y modelos</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Aprendizaje máquina supervisado con R</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Fundamentos</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-introduccion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-ml-supervisado.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Aprendizaje máquina supervisado</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-algoritmos-modelos.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Algoritmos y modelos</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-seleccion-validacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Selección y validación de modelos</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Métodos convencionales</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-modelos-clasicos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelos clásicos</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-modelos-avanzados.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos avanzados</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Tidymodels</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-tidymodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tidymodels</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Otros entornos</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-mlr3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">MLR3</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-add-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Recursos adicionales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Apéndices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A-command-ref.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Referencia de comandos</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B-packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Paquetes R empleados</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-refs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#k-vecinos-más-cercanos-k-nn" id="toc-k-vecinos-más-cercanos-k-nn" class="nav-link active" data-scroll-target="#k-vecinos-más-cercanos-k-nn"><span class="header-section-number">3.1</span> K vecinos más cercanos (K-NN)</a></li>
  <li><a href="#modelos-lineales" id="toc-modelos-lineales" class="nav-link" data-scroll-target="#modelos-lineales"><span class="header-section-number">3.2</span> Modelos lineales</a>
  <ul class="collapse">
  <li><a href="#regularización-en-modelos-lineales" id="toc-regularización-en-modelos-lineales" class="nav-link" data-scroll-target="#regularización-en-modelos-lineales"><span class="header-section-number">3.2.1</span> Regularización en modelos lineales</a></li>
  </ul></li>
  <li><a href="#extensiones-del-modelo-lineal" id="toc-extensiones-del-modelo-lineal" class="nav-link" data-scroll-target="#extensiones-del-modelo-lineal"><span class="header-section-number">3.3</span> Extensiones del modelo lineal</a></li>
  <li><a href="#máquinas-de-vector-soporte-svm" id="toc-máquinas-de-vector-soporte-svm" class="nav-link" data-scroll-target="#máquinas-de-vector-soporte-svm"><span class="header-section-number">3.4</span> Máquinas de vector soporte (SVM)</a></li>
  <li><a href="#modelos-probabilísticos-naïve-bayes" id="toc-modelos-probabilísticos-naïve-bayes" class="nav-link" data-scroll-target="#modelos-probabilísticos-naïve-bayes"><span class="header-section-number">3.5</span> Modelos probabilísticos: Naïve Bayes</a></li>
  <li><a href="#redes-neuronales-y-aprendizaje-profundo" id="toc-redes-neuronales-y-aprendizaje-profundo" class="nav-link" data-scroll-target="#redes-neuronales-y-aprendizaje-profundo"><span class="header-section-number">3.6</span> Redes neuronales y aprendizaje profundo</a></li>
  <li><a href="#ensamblado-de-modelos" id="toc-ensamblado-de-modelos" class="nav-link" data-scroll-target="#ensamblado-de-modelos"><span class="header-section-number">3.7</span> Ensamblado de modelos</a></li>
  <li><a href="#apilado-de-modelos" id="toc-apilado-de-modelos" class="nav-link" data-scroll-target="#apilado-de-modelos"><span class="header-section-number">3.8</span> Apilado de modelos</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-introduccion.html">Fundamentos</a></li><li class="breadcrumb-item"><a href="./03-algoritmos-modelos.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Algoritmos y modelos</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Algoritmos y modelos</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>En este apartado, vamos a presentar algunos modelos de aprendizaje máquina supervisado que, posteriormente, mostraremos cómo se pueden entrenar y evaluar con R.</p>
<p>Antes de comenzar, es importante hacer una distinción entre dos tipos de modelos o algoritmos <span class="citation" data-cites="james2021">(<a href="references.html#ref-james2021" role="doc-biblioref">James, 2021</a>)</span>:</p>
<ul>
<li><p><strong>Modelos paramétricos</strong>: son aquellos en los que se utiliza una función <span class="math inline">\(f(X)\)</span> para predecir la salida, cuya forma viene determinada por una serie de parámetros que podemos ajustar a partir de los datos. Un ejemplo sería un modelo de regresión lineal.</p></li>
<li><p><strong>Modelos no paramétricos</strong>: estos no asumen una forma paramétrica para la función de predicción <span class="math inline">\(f(X)\)</span>, ofreciendo una alternativa más flexible para resolver el problema de regresión.</p></li>
</ul>
<section id="k-vecinos-más-cercanos-k-nn" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="k-vecinos-más-cercanos-k-nn"><span class="header-section-number">3.1</span> K vecinos más cercanos (K-NN)</h2>
<p>Se trata de un modelo que puede realizar funciones de regresión o clasificación. En el caso de la regresión, fijado un valor para <span class="math inline">\(K\)</span> y un punto de predicción <span class="math inline">\(x_0\)</span>, se identifican las <span class="math inline">\(K\)</span> observaciones del conjunto de entrenamiento más cercanas a <span class="math inline">\(x_0\)</span>, denotadas por <span class="math inline">\(\mathcal{N}_0\)</span>. Entonces, se estima <span class="math inline">\(f(x_0)\)</span> como el valor promedio de todas las respuestas contenidas en <span class="math inline">\(\mathcal{N}_0\)</span>, es decir:</p>
<p><span id="eq-KNN"><span class="math display">\[
\hat{f}(x_0) = \frac{1}{K}\sum_{x_i \in \mathcal{N}_0} \,y_i.
\tag{3.1}\]</span></span></p>
<div id="fig-KNN-fit" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-KNN-fit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/KNN-fit-ISLRv2.png" class="img-fluid figure-img" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-KNN-fit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.1: Valores estimados para una regresión KNN en un conjunto de datos en dos dimensiones con 64 observaciones. Izq.: K=1. Dcha.: K=9. Fuente: Fig. 3.16 <span class="citation" data-cites="james2021">(<a href="references.html#ref-james2021" role="doc-biblioref">James, 2021</a>)</span>.
</figcaption>
</figure>
</div>
<p>Este modelo se basa en la premisa de que las observaciones similares se encontrarán próximas entre sí dentro del espacio de representación de los datos. Sin embargo, no siempre es fácil encontrar espacios de representación que describan nuestro problema de forma adecuada para que se cumpla esta premisa. En todo caso, este modelo ha demostrado ser muy útil en gran variedad de problemas.</p>
<p>En la <a href="https://bradleyboehmke.github.io/HOML/knn.html#measuring-similarity">Sec. 8.2</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>, se discuten algunas medidas de disimilaridad que se pueden computar entre pares de observaciones. Algunas funciones de distancia son la familia de distancias Minkowski, incluyendo Manhattan (L1), Euclídea (L2) o Chebyshev (Linf); la distancia de Haversine (para datos geolocalizados sobre la superficie terrestre); la similaridad del coseno (para documentos o datos textuales) o la distancia de Jaccard.</p>
</section>
<section id="modelos-lineales" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="modelos-lineales"><span class="header-section-number">3.2</span> Modelos lineales</h2>
<p>Los modelos lineales asumen que existe una relación lineal entre las variables de entrada (<em>inputs</em>, <em>features</em>) y la salida que se desea predecir. Cuidado, porque esto no implica necesariamente que la forma de la función ajustada sea una línea recta, una confusión bastante común que suele asaltar a muchas personas.</p>
<p>El dos ejemplos muy básicos de este tipo de modelos son la regresión lineal simple y la regresión lineal múltiple, presentados en detalle en el <a href="https://bradleyboehmke.github.io/HOML/linear-regression.html">Capítulo 4</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>, así como en el Capítulo 3 de <span class="citation" data-cites="james2021">(<a href="references.html#ref-james2021" role="doc-biblioref">James, 2021</a>)</span>. Sin embargo, un polinomio de grado (parábola) sigue siendo un modelo lineal ya que, aunque su forma son sea una línea recta, la ecuación se sigue expresando como una combinación lineal de varias componentes.</p>
<p>Los Modelos Lineales Generalizados (GLM por sus siglas en inglés) extienden el modelo lineal original para responder a muchos tipos de problemas: variables respuesta que no siguen una distribución normal, relaciones no lineales (no recta) entre las entradas y la variable de salida, o salidas de tipo categórico (binarias, multinomiales, ordenadas, etc.).</p>
<p>Este tipo de modelos consta de tres elementos <span class="citation" data-cites="agresti2015">(<a href="references.html#ref-agresti2015" role="doc-biblioref">Agresti, 2015</a>)</span>:</p>
<ul>
<li><p><strong>Función de enlace</strong>: define una conexión entre el valor esperado (media) de la variable respuesta con la combinación lineal de las variables de entrada, lo que permite definir modelos que no sigan la forma de una recta (más flexibles), capturando relaciones más complejas.</p></li>
<li><p><strong>Distribución de probabilidad</strong> (componente aleatoria): describe el “ruido” o variabilidad de los datos alrededor del valor promedio que se predice. Distribuciones habituales son la Normal, Binomial o Poisson.</p></li>
<li><p><strong>Estructura lineal</strong>: todas las variables de entrada se relacionan entre sí mediante una combinación lineal, ponderadas por coeficientes que se ajustan a partir de los datos de entrenamiento. Sin embargo, la estructura generalizada del modelo permite asumir formas no lineales, así como incorporar variables de entrada categóricas, mediante la codificación adecuada.</p></li>
</ul>
<p>La <a href="#tbl-my" class="quarto-xref">Tabla&nbsp;<span>3.1</span></a> presenta algunos modelos GLM frecuentemente empleados.</p>
<div id="tbl-my" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-my-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;3.1: Algunos modelos GLM y sus elementos constitutivos asociados.
</figcaption>
<div aria-describedby="tbl-my-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 24%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Modelo</th>
<th style="text-align: left;">Comp. aleatoria</th>
<th style="text-align: left;">Col3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Regresión lineal</td>
<td style="text-align: left;">Normal</td>
<td style="text-align: left;">Cuantitativas o cualitativas</td>
</tr>
<tr class="even">
<td style="text-align: left;">Regresión logística</td>
<td style="text-align: left;">Binomial</td>
<td style="text-align: left;">Cuantitativas o cualitativas</td>
</tr>
<tr class="odd">
<td style="text-align: left;">LogLinear</td>
<td style="text-align: left;">Poisson</td>
<td style="text-align: left;">Cualitativas</td>
</tr>
<tr class="even">
<td style="text-align: left;">Reg. de Poisson</td>
<td style="text-align: left;">Poisson</td>
<td style="text-align: left;">Cuantitativas o cualitativas</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<section id="regularización-en-modelos-lineales" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="regularización-en-modelos-lineales"><span class="header-section-number">3.2.1</span> Regularización en modelos lineales</h3>
<p>En los conjuntos de datos actuales, normalmente de gran tamaño, existe el riesgo de que los modelos lineales tiendan al sobreajuste de los datos de entrenamiento, incrementando nuestro error de generalización. Una estrategia muy útil para restringir este efecto pernicioso es la <strong>regularización</strong> del modelo, que consiste en aplicar una serie de “penalizaciones” a los coeficientes estimados para reducir la varianza (dentro del compromiso varianza-sesgo) y así mantener a raya el problema del sobreajuste.</p>
<p>Tres opciones muy comunes de regularización son:</p>
<ul>
<li><p>Penalización Ridge: modifica la función objetivo de ajuste del modelo con un término controlado por un hiperparámetro <span class="math inline">\(\lambda\)</span>. Cuanto más crece el valor asignado a <span class="math inline">\(\lambda\)</span> más se fuerza a que los coeficientes del modelo se vayan haciendo cada vez más pequeños, aunque sin llegar a anularse. Véase el <a href="https://bradleyboehmke.github.io/HOML/regularized-regression.html#why">Apartado 6.2.1</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>.</p></li>
<li><p>Penalización Lasso: altera la función objetivo para ajustar el modelo con un térmio también controlado por un hiperparámetro <span class="math inline">\(\lambda\)</span>. Sin embargo, al contrario que en el caso anterior, cuando <span class="math inline">\(\lambda\)</span> crece se van anulando progresivamente más coeficientes de la función de predicción, lo que constituye un método más drástico de selección de variables y simplificación de nuestro modelo. Véase el <a href="https://bradleyboehmke.github.io/HOML/regularized-regression.html#why">Apartado 6.2.2</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>.</p></li>
<li><p><em>Elastic net</em>: es una solución intermedia entre los dos casos anteriores, introduciendo simultáneamente ambos tipos de penalización (Ridge y Lasso), cada uno de ellos controlado por un hiperparámetro de penalización, <span class="math inline">\(\lambda_1\)</span> y <span class="math inline">\(\lambda_2\)</span>, respectivamente. Véase el <a href="https://bradleyboehmke.github.io/HOML/regularized-regression.html#why">Apartado 6.2.3</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>.</p></li>
</ul>
<p>En la <a href="#fig-ridge-lasso-contours" class="quarto-xref">Figura&nbsp;<span>3.2</span></a> se representan los errores (todos los puntos sobre una elipse tienen el mismo valor de RSS) y las funciones de restricción impuestas en el caso de la penalización Lasso y Ridge. Podemos observar como en el caso del Lasso las restricciones tienen aristas, lo que hace que la intersección entre el contorno y la región de restricción se produzca sobre el eje. Cuando esto ocurre, los coeficientes de la función de regresión se anulan. Sin embargo, en Ridge el punto de intersección no llega a tocar el eje, por lo que los coeficientes no llegan a anularse.</p>
<div id="fig-ridge-lasso-contours" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ridge-lasso-contours-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/ridge-lasso-contours.png" class="img-fluid figure-img" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ridge-lasso-contours-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.2: Gráficos de contorno para los errores en las estimaciones y funciones de restricción para Lasso (izq.) y Ridge (dcha.). Fuente: Fig. 6.7 <span class="citation" data-cites="james2021">(<a href="references.html#ref-james2021" role="doc-biblioref">James, 2021</a>)</span>.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="extensiones-del-modelo-lineal" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="extensiones-del-modelo-lineal"><span class="header-section-number">3.3</span> Extensiones del modelo lineal</h2>
<p>Además de los modelos polinómicos o los GLM descritos anteriormente, existen más extensiones de los modelos lineales. La aproximación común a muchos de ellos es utilizar funciones polinómicas con formas suaves para ir ajustando tramos de la función de predicción. En consecuencia, la superposición (combinación lineal) de estas funciones suaves dará como resultado un modelo tremendamente flexible que se puede adaptar a problemas muy complicados.</p>
<p>Un primer ejemplo son los modelos MARS (<em>Multivariate Adaptive Regression Splines</em>), presentados en el <a href="https://bradleyboehmke.github.io/HOML/mars.html#the-basic-idea">Capítulo 7</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>. Otro ejemplo son los modelos GAM (<em>Generalized Additive Models</em>) que se explican en la Sección 7.7 de <span class="citation" data-cites="james2021">(<a href="references.html#ref-james2021" role="doc-biblioref">James, 2021</a>)</span>. En el caso de estos últimos se extiende el modelo lineal manteniendo la combinación aditiva (suma) de los componentes de predicción. Sin embargo, en cada componente se emplea una función lineal <span class="math inline">\(f_j(x_{ij})\)</span>, cuya forma debemos estimar a partir de los datos, según la <a href="#eq-GAM" class="quarto-xref">Ecuación&nbsp;<span>3.2</span></a>:</p>
<p><span id="eq-GAM"><span class="math display">\[
y_i = \beta_0 + \sum_{j=1}^{p}f_j(x_{ij})+\epsilon_i
\tag{3.2}\]</span></span></p>
<p>La <a href="#fig-example-GAM-fit" class="quarto-xref">Figura&nbsp;<span>3.3</span></a> muestra un ejemplo del resultado de ajustar un modelo GAM utilizando dos variables de entrada cuantitativas y una cualitativa.</p>
<div id="fig-example-GAM-fit" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-example-GAM-fit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/example-GAM-fit.png" class="img-fluid figure-img" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-example-GAM-fit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.3: Ejemplo de ajuste de un modelo GAM, con dos predictores cuantitativos (izq. y centro) y otro cualitativo (dcha.). Se puede apreciar que las funciones para los predictores cuantiativos son flexibles y suaves. Fuente: Fig. 7.12 <span class="citation" data-cites="james2021">(<a href="references.html#ref-james2021" role="doc-biblioref">James, 2021</a>)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="máquinas-de-vector-soporte-svm" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="máquinas-de-vector-soporte-svm"><span class="header-section-number">3.4</span> Máquinas de vector soporte (SVM)</h2>
<p>Las SVM son ejemplos de modelos de clasificación (salida cualitativa), en los que el objetivo es encontrar un hiperplano que separe de la mejor forma posible los elementos pertenecientes a dos grupos (asumiendo que la salida es una variable binaria).</p>
<p>La <a href="#fig-svm-hmc1" class="quarto-xref">Figura&nbsp;<span>3.4</span></a> muestra cómo se identifican los llamados “vectores soporte” para definir la frontera de separación entre los puntos pertenecientes a los dos grupos de la variable de salida, para el caso de un clasficador de margen rígido (es decir, que no admite que puntos de uno de los grupos desborden la frontera con el otro grupo).</p>
<div id="fig-svm-hmc1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-svm-hmc1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/svm-hmc-1.png" class="img-fluid figure-img" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-svm-hmc1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.4: Ilustración del método para encontrar los vectores soporte, que definen la frontera de separación entre los dos grupos de la variable de salida en un modelo SVM. Se asume un clasficador de margen rígido (HMC). Fuente: Fig. 14.3 <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>.
</figcaption>
</figure>
</div>
<p>Lo normal es utilizar una versión más flexible de este algoritmo, que tolera que existan puntos mal clasificados (i.e.&nbsp;en el lado incorrecto de la frontera), dentro de un cierto margen de error. No obstante, la verdadera clave de estos modelos es que aplican el llamado <strong><em>kernel trick</em></strong>, una argucia matemática que nos permite representar los datos en un espacio alternativo en el que la separación entre las fronteras sea calculable. Matemáticamente, entender esta herramienta implica el manejo de <em>funciones núcleo</em> (<em>kernel functions</em>) y comprender los Espacios de Hilbert de Núcleo Reproductor (RKHS). Puedes consultar estos <a href="https://www.gatsby.ucl.ac.uk/~gretton/coursefiles/lecture4_introToRKHS.pdf">apuntes de un profesor de UCL</a> para una introducción a estos temas.</p>
<p>En la práctica, el hecho de que no podamos apreciar directamente los detalles del espacio alternativo en el que se están representando los datos hace que a estos modelos se les considere en cierta medida como de “caja negra” (<em>black-box models</em>). En consecuencia, otras de las limitaciones es que no resulta nada evidente explicar el papel que juega cada una de las variables en la identificación de la frontera de separación entre clases.</p>
<div id="fig-two-spirals-SVM" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-two-spirals-SVM-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/two-spirals-SVM.png" class="img-fluid figure-img" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-two-spirals-SVM-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.5: Fronteras de separación entre dos grupos de datos que se organizan en forma de espiral. Izq.: frontera de clasificación determinada mediante un algoritmo RF. Dcha.: frontera de clasificación identificada mediante un algoritmo SVM que usa una función núcleo de base radial (<em>radial basis kernel</em>). Fuente: Fig. 14.7 <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="modelos-probabilísticos-naïve-bayes" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="modelos-probabilísticos-naïve-bayes"><span class="header-section-number">3.5</span> Modelos probabilísticos: Naïve Bayes</h2>
<p>Un ejemplo de modelos de clasificación probabilísticos es el llamado Naïve Bayes (Bayes ingenuo), cuyo funcionamiento se basa en una aplicación directa del Teorema de Bayes. Se emplean con frecuencia en problemas de clasificación con datos textuales, cuando tenemos muchas variables de entrada o bien cuando el rango de valores de las variables de entrada es muy amplio.</p>
<p>Recordemos que el Teorema de Bayes viene dado por:</p>
<p><span id="eq-Bayes-theorem"><span class="math display">\[
P(B \mid A) = \frac{P(B)P(A \mid B)}{P(A)}
\tag{3.3}\]</span></span></p>
<p>Si consideramos que las variables predictoras son independientes entre sí, entonces tenemos que la fórmula de predicción es:</p>
<p><span id="eq-Naive-Bayes"><span class="math display">\[
P(Y_k \mid X_1, \dots, X_p) = \frac{P(Y_k)\prod_{j=1}^p P(X_j \mid Y_k)}{P(X_1, X_2, \dots, X_p)}
\tag{3.4}\]</span></span></p>
<p>Puesto que el denominador es una constante, nos centramos en calcular el valor del numerador para poder comparar las probabilidades condicionadas a los valores de las variables de entrada. La clase predicha maximiza la expresión:</p>
<p><span class="math display">\[
\underset{x}{\arg\max} \left\{ P(Y_k) \prod_{j=1}^p P(X_j \mid Y_k)\right\}.
\]</span></p>
</section>
<section id="redes-neuronales-y-aprendizaje-profundo" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="redes-neuronales-y-aprendizaje-profundo"><span class="header-section-number">3.6</span> Redes neuronales y aprendizaje profundo</h2>
<p>Muchos modelos de aprendizaje automático solamente incorporan una o dos capas de transformación de datos para aprender la representación de los datos de salida. Estos modelos se denominan superficiales (<em>shallow models</em>). En contraste, los <strong>modelos profundos</strong> (<em>deep models</em>) siguen una aproximación multicapa para aprender las representaciones de los datos. El caso más habitual es el de usar múltiples capas de <strong>redes neuronales</strong>. El <a href="https://bradleyboehmke.github.io/HOML/deep-learning.html">Capítulo 13</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span> y el Capítulo 10 de <span class="citation" data-cites="james2021">(<a href="references.html#ref-james2021" role="doc-biblioref">James, 2021</a>)</span> proporcionan dos buenas introducciones a este tipo de modelos.</p>
<p>La <a href="#fig-multi-layer-NN" class="quarto-xref">Figura&nbsp;<span>3.6</span></a> muestra el diseño de una red neuronal con dos capas ocultas que podría utilizarse para predecir los 10 posibles valores de salida del dataset MNIST, con imágenes de cifras manuscritas.</p>
<div id="fig-multi-layer-NN" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-multi-layer-NN-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/multi-layer-NN.png" class="img-fluid figure-img" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-multi-layer-NN-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.6: Esquema de un modelo de clasificación basado en una red neuronal con dos capas ocultas y varias posibles salidas, que se puede aplicar al conjunto de datos MNIST de cifras manuscritas. Fuente: Fig. 10.4 <span class="citation" data-cites="james2021">(<a href="references.html#ref-james2021" role="doc-biblioref">James, 2021</a>)</span>.
</figcaption>
</figure>
</div>
<p>La clave para que una red neuronal de aprendizaje profundo se autoajuste en base a los datos de entrenamiento es un proceso denominado <strong>retropropagación</strong> (<em>backpropagation</em>). Este proceso se explica, por ejemplo, en la <a href="https://bradleyboehmke.github.io/HOML/deep-learning.html#dl-back">Sec. 13.5</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>, así como en la Sec. 10.7.1 de <span class="citation" data-cites="james2021">(<a href="references.html#ref-james2021" role="doc-biblioref">James, 2021</a>)</span>, entre otras muchas fuentes.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Videotutorial sobre aprendizaje profundo
</div>
</div>
<div class="callout-body-container callout-body">
<p>El sitio web <a href="https://www.3blue1brown.com/" class="uri">https://www.3blue1brown.com/</a> contiene un extenso catálogo de videotutoriales y sesiones formativas sobrfe muchos temas de interés, como redes neuronales, álgebra o cálculo.</p>
<p>El vídeo <a href="https://www.3blue1brown.com/?v=backpropagation">What is backpropagation really doing?</a> es una de las mejores explicaciones intuitivas para entender mejor el papel de la retropropagación en el entrenamiento de redes neuronales para aprendizaje profundo.</p>
</div>
</div>
</section>
<section id="ensamblado-de-modelos" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="ensamblado-de-modelos"><span class="header-section-number">3.7</span> Ensamblado de modelos</h2>
<p>El ensamblado de modelos es una aproximación para resolver el problema del aprendizaje máquina que consiste en combinar la salida de múltiples modelos individuales para dar una predicción final que mejora el rendimiento que podríamos alcanzar con un solo modelo. La referencia más completa para entender bien esta estrategia de aprendizaje máquina es <span class="citation" data-cites="kuncheva2014">(<a href="references.html#ref-kuncheva2014" role="doc-biblioref">Kuncheva, 2014</a>)</span>.</p>
<p>Algunos de los modelos más conocidos son:</p>
<ul>
<li><p><em>Bagging</em> (<em>Bootstrap AGGregatING): consiste en el ensamblado de modelos de clasificación entrenados sobre réplicas </em>bootstrap* de los datos de entrenamiento originales. La salida de los clasificadores individuales se combina mediante el voto de pluralidad. Utilizar el voto mayoritario para tomar la decisión garantiza que vamos a obtener un resultado que mejora el de cada modelo individual. El <a href="https://bradleyboehmke.github.io/HOML/bagging.html">Capítulo 10</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span> muestra en detalle ejemplos de esta técnica.</p></li>
<li><p><em>Random Forests</em> (bosques aleatorios): fueron propuestos por el insigne Leo Breiman en 2001 <span class="citation" data-cites="breiman2001random">(<a href="references.html#ref-breiman2001random" role="doc-biblioref">Breiman, 2001</a>)</span>. Es una modificación de la estrategia de <em>bagging</em> aplicada a modelos de árboles de decisión, que emplea una amplia colección de árboles <em>decorrelados entre sí</em> para mejorar la eficiencia de predicción de la variable de salida. Además de tomar muestras <em>bootstrap</em> de los datos de entrenamiento, este método realiza selecciones aleatorias de las variables de entrada <em>en cada nodo del árbol</em>, tras lo cual se selecciona de entre las características tomadas la azar la mejor para dividir los caminos desde ese nodo. Es uno de los métodos más populares hoy en día, puesto que ofrece un buen rendimiento con un coste computacional contenido y con relativamente poco esfuerzo de ajuste de hiperparámetros. El <a href="https://bradleyboehmke.github.io/HOML/random-forest.html">Capítulo 11</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span> muestra el trabajo con este tipo de algoritmos.</p></li>
<li><p><em>Boosting</em>: propone la construcción de un ensamblado de árboles poco profundos, secuencialmente, en el que cada árbol que se añade mejora al anterior. Aunque cada árbol poco profundo es una herramienta de aprendizaje débil, pueden ser “potenciados” (<em>boosted</em>) de este modo para crear un comité de modelos que ofrece un rendimiento muy bueno. Uno de los primeros métodos propuestos con esta estrategia fue AdaBoost. Una de las variantes más populares actualmente es XGBoost (<em>Extreme Gradient Boosting</em>) (véase <a href="https://bradleyboehmke.github.io/HOML/gbm.html#xgboost">Sec. 12.5</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span>), que incluye hiperparámetros para controlar términos de penalización del modelo que reduzcan su complejidad y prevengan el sobreajuste.</p></li>
</ul>
</section>
<section id="apilado-de-modelos" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="apilado-de-modelos"><span class="header-section-number">3.8</span> Apilado de modelos</h2>
<p>Por último, otra posible estrategia de combinación de modelos de aprendizaje individuales es el <strong>apilado de modelos</strong> (<em>model stacking</em>), que implica el entrenamiento de un nuevo modelo que combina las predicciones de varios modelos de aprendizaje de base. El meta-algoritmo que combina las salidas previas, llamado <em>super learner</em> permite mejorar aún más el rendimiento de los modelos de aprendizaje de base (como RF o XGBoost). En el <a href="https://bradleyboehmke.github.io/HOML/stacking.html">Capítulo 15</a> de <span class="citation" data-cites="boehmke2019">(<a href="references.html#ref-boehmke2019" role="doc-biblioref">Boehmke &amp; Greenwell, 2019</a>)</span> se puede encontrar más información y ejemplos de este tipo de modelos.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list" style="display: none">
<div id="ref-agresti2015" class="csl-entry" role="listitem">
Agresti, A. (2015). <em><span>Foundations of Linear and Generalized Linear Models</span></em> (1.ª ed.). John Wiley &amp; Sons.
</div>
<div id="ref-boehmke2019" class="csl-entry" role="listitem">
Boehmke, B., &amp; Greenwell, B. (2019). <em>Hands-On Machine Learning with R</em> (1.ª ed.). Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9780367816377">https://doi.org/10.1201/9780367816377</a>
</div>
<div id="ref-breiman2001random" class="csl-entry" role="listitem">
Breiman, L. (2001). Random forests. <em>Machine learning</em>, <em>45</em>(1), 5-32.
</div>
<div id="ref-james2021" class="csl-entry" role="listitem">
James, W., G. (2021). <em><span>An Introduction to Statistical Learning with Applications in R</span></em> (2.ª ed.). Springer. <a href="https://www.statlearning.com/">https://www.statlearning.com/</a>
</div>
<div id="ref-kuncheva2014" class="csl-entry" role="listitem">
Kuncheva, L. I. (2014). <em>Combining Pattern Classifiers: Methods and Algorithms</em> (2.ª ed.). Wiley-Interscience. <a href="https://lucykuncheva.co.uk/Combining_Pattern_Classifiers_Methods_and_Algorithms_2nd_ed_Kuncheva%202014-09-09.pdf">https://lucykuncheva.co.uk/Combining_Pattern_Classifiers_Methods_and_Algorithms_2nd_ed_Kuncheva%202014-09-09.pdf</a>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-ml-supervisado.html" class="pagination-link" aria-label="Aprendizaje máquina supervisado">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Aprendizaje máquina supervisado</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./04-seleccion-validacion.html" class="pagination-link" aria-label="Selección y validación de modelos">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Selección y validación de modelos</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>